<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.433">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Vladimir Orlenko">
<meta name="dcterms.date" content="2023-07-29">

<title>ml-blog - Create Mario Levels</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-dark.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="dark">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>


<link rel="stylesheet" href="../../styles.css">
</head>

<body class="nav-fixed fullcontent">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container">
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">ml-blog</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../about.html" rel="" target="">
 <span class="menu-text">About</span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/vorlenko" rel="" target=""><i class="bi bi-github" role="img">
</i> 
 <span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://www.linkedin.com/in/vladimir-orlenko-9674507/" rel="" target=""><i class="bi bi-linkedin" role="img">
</i> 
 <span class="menu-text"></span></a>
  </li>  
</ul>
            <div class="quarto-navbar-tools">
</div>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <h1 class="title">Create Mario Levels</h1>
                                <div class="quarto-categories">
                <div class="quarto-category">code</div>
              </div>
                  </div>
  </div>
    
  
  <div class="quarto-title-meta">

      <div>
      <div class="quarto-title-meta-heading">Author</div>
      <div class="quarto-title-meta-contents">
               <p>Vladimir Orlenko </p>
            </div>
    </div>
      
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">July 29, 2023</p>
      </div>
    </div>
    
      
    </div>
    
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    
<!-- main -->
<main class="content quarto-banner-title-block" id="quarto-document-content">




<p>Рассмотрим применение RNN для создания игровых уровней</p>
<p>по этому <a href="https://nesmaps.com/maps/SuperMarioBrothers/SuperMarioBrothers.html">адресу</a> размещены карты уровней Супер Марио.</p>
<p>Возьмем от-туда <a href="https://nesmaps.com/maps/SuperMarioBrothers/SuperMarioBrosMap1-1.png">карту</a></p>
<p><img src="https://nesmaps.com/maps/SuperMarioBrothers/SuperMarioBrosMap1-1.png"></p>
<p>Откроем ее в gimp. Включим сетку, и текстом прокодируем спрайты</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="rnn_mario_level_builder_files/figure-html/9c634889-1-72642b76-41ab-4495-b71e-54f2bf9880e6.png" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">image.png</figcaption>
</figure>
</div>
<p>В результате получаем текстовый файл описывающий препятствия</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="rnn_mario_level_builder_files/figure-html/4636360d-1-500d0f68-3e01-487f-8edc-f51998c2b4e2.png" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">image.png</figcaption>
</figure>
</div>
<p>Сохраним его, и приступим к написанию кода</p>
<p>Сначала мы загрузим данные уровня в переменную <code>Level</code></p>
<div class="cell" data-executioninfo="{&quot;elapsed&quot;:3331,&quot;status&quot;:&quot;ok&quot;,&quot;timestamp&quot;:1673065074030,&quot;user&quot;:{&quot;displayName&quot;:&quot;Vladimir Orlenko&quot;,&quot;userId&quot;:&quot;14647639487768811794&quot;},&quot;user_tz&quot;:-360}" data-outputid="bb8bb753-23b9-483c-c084-543aef88cfab">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a>fname <span class="op">=</span> <span class="st">'/content/drive/MyDrive/Проекты/ML/Pets/rnn_mario_level_builder/data/MarioL1_.txt'</span></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="co">#np.loadtxt(fname, dtype=’float’, comments=’#’, delimiter=None, converters=None, skiprows=0, usecols=None, unpack=False, ndmin=0 encoding='bytes', max_rows=None)</span></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a>Level <span class="op">=</span> np.loadtxt(fname, dtype<span class="op">=</span><span class="st">'str'</span>,comments<span class="op">=</span><span class="va">None</span>) </span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(Level)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>['--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------'
 '--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------'
 '--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------'
 '------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|-------------------------'
 '------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|-------------------------'
 '----------------------?---------------------------------------------------------========---===?--------------?-----------===----=??=--------------------------------------------------------##--------|-------------------------'
 '-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------###--------|-------------------------'
 '------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------####--------|-------------------------'
 '-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------#####--------|----\\\\\\------------------'
 '----------------?---=-=?=---------------------PP---------PP------------------=?=--------------=-----==----?--?--?-----=----------==------#--#----------##--#------------==?=------------######--------|----CSD------------------'
 '--------------------------------------PP------PP---------PP-----------------------------------------------------------------------------##--##--------###--##--------------------------#######--------|---\\\\\\\\\\-----------------'
 '----------------------------PP--------PP------PP---------PP----------------------------------------------------------------------------###--###------####--###-----PP--------------PP-########--------|---SSUSS-----------------'
 '----------------------------PP--------PP------PP---------PP---------------------------------------------------------------------------####--####----#####--####----PP--------------PP#########--------#---SSOSS-----------------'
 'GGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGG--GGGGGGGGGGGGGGG---GGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGG--GGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGG'
 'GGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGG--GGGGGGGGGGGGGGG---GGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGG--GGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGG']</code></pre>
</div>
</div>
<p>Данные не годятся для обучения, так как у нас всего 15 строк и 255 признаков. Если повернем набор, то у нас будет 15 признаков и 255 строк, что уже лучше.</p>
<div class="cell" data-executioninfo="{&quot;elapsed&quot;:788,&quot;status&quot;:&quot;ok&quot;,&quot;timestamp&quot;:1673065089264,&quot;user&quot;:{&quot;displayName&quot;:&quot;Vladimir Orlenko&quot;,&quot;userId&quot;:&quot;14647639487768811794&quot;},&quot;user_tz&quot;:-360}" data-outputid="196a3a27-07c2-4b1b-e149-fabe21baaf2e">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a>col<span class="op">=</span><span class="bu">len</span>(Level[<span class="dv">0</span>])</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>row<span class="op">=</span><span class="bu">len</span>(Level)</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a>Level.shape</span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a>LevelP<span class="op">=</span>np.zeros((row,col), dtype<span class="op">=</span><span class="st">'S1'</span>)</span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(LevelP.shape)</span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(row):</span>
<span id="cb3-11"><a href="#cb3-11" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb3-12"><a href="#cb3-12" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> j <span class="kw">in</span> <span class="bu">range</span>(col):</span>
<span id="cb3-13"><a href="#cb3-13" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb3-14"><a href="#cb3-14" aria-hidden="true" tabindex="-1"></a>    LevelP[i,j]<span class="op">=</span>Level[i][col<span class="op">-</span>j<span class="op">-</span><span class="dv">1</span>]</span>
<span id="cb3-15"><a href="#cb3-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-16"><a href="#cb3-16" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> np.printoptions(threshold<span class="op">=</span>np.inf, linewidth<span class="op">=</span><span class="dv">1275</span>):</span>
<span id="cb3-17"><a href="#cb3-17" aria-hidden="true" tabindex="-1"></a>  <span class="bu">print</span>(LevelP)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>(15, 224)
[[b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-']
 [b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-']
 [b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-']
 [b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'|' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-']
 [b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'|' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-']
 [b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'|' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'#' b'#' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'=' b'?' b'?' b'=' b'-' b'-' b'-' b'-' b'=' b'=' b'=' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'?' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'?' b'=' b'=' b'=' b'-' b'-' b'-' b'=' b'=' b'=' b'=' b'=' b'=' b'=' b'=' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'?' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-']
 [b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'|' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'#' b'#' b'#' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-']
 [b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'|' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'#' b'#' b'#' b'#' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-']
 [b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'\\' b'\\' b'\\' b'-' b'-' b'-' b'-' b'|' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'#' b'#' b'#' b'#' b'#' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-']
 [b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'D' b'S' b'C' b'-' b'-' b'-' b'-' b'|' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'#' b'#' b'#' b'#' b'#' b'#' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'=' b'?' b'=' b'=' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'#' b'-' b'-' b'#' b'#' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'#' b'-' b'-' b'#' b'-' b'-' b'-' b'-' b'-' b'-' b'=' b'=' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'=' b'-' b'-' b'-' b'-' b'-' b'?' b'-' b'-' b'?' b'-' b'-' b'?' b'-' b'-' b'-' b'-' b'=' b'=' b'-' b'-' b'-' b'-' b'-' b'=' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'=' b'?' b'=' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'P' b'P' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'P' b'P' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'=' b'?' b'=' b'-' b'=' b'-' b'-' b'-' b'?' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-']
 [b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'\\' b'\\' b'\\' b'\\' b'\\' b'-' b'-' b'-' b'|' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'#' b'#' b'#' b'#' b'#' b'#' b'#' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'#' b'#' b'-' b'-' b'#' b'#' b'#' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'#' b'#' b'-' b'-' b'#' b'#' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'P' b'P' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'P' b'P' b'-' b'-' b'-' b'-' b'-' b'-' b'P' b'P' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-']
 [b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'S' b'S' b'U' b'S' b'S' b'-' b'-' b'-' b'|' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'#' b'#' b'#' b'#' b'#' b'#' b'#' b'#' b'-' b'P' b'P' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'P' b'P' b'-' b'-' b'-' b'-' b'-' b'#' b'#' b'#' b'-' b'-' b'#' b'#' b'#' b'#' b'-' b'-' b'-' b'-' b'-' b'-' b'#' b'#' b'#' b'-' b'-' b'#' b'#' b'#' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'P' b'P' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'P' b'P' b'-' b'-' b'-' b'-' b'-' b'-' b'P' b'P' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'P' b'P' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-']
 [b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'S' b'S' b'O' b'S' b'S' b'-' b'-' b'-' b'#' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'#' b'#' b'#' b'#' b'#' b'#' b'#' b'#' b'#' b'P' b'P' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'P' b'P' b'-' b'-' b'-' b'-' b'#' b'#' b'#' b'#' b'-' b'-' b'#' b'#' b'#' b'#' b'#' b'-' b'-' b'-' b'-' b'#' b'#' b'#' b'#' b'-' b'-' b'#' b'#' b'#' b'#' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'P' b'P' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'P' b'P' b'-' b'-' b'-' b'-' b'-' b'-' b'P' b'P' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'P' b'P' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-' b'-']
 [b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'-' b'-' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'-' b'-' b'-' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'-' b'-' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G']
 [b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'-' b'-' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'-' b'-' b'-' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'-' b'-' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G' b'G']]</code></pre>
</div>
</div>
<div class="cell" data-executioninfo="{&quot;elapsed&quot;:605,&quot;status&quot;:&quot;ok&quot;,&quot;timestamp&quot;:1673065104855,&quot;user&quot;:{&quot;displayName&quot;:&quot;Vladimir Orlenko&quot;,&quot;userId&quot;:&quot;14647639487768811794&quot;},&quot;user_tz&quot;:-360}" data-outputid="f387286a-5ef7-46be-d289-7ca451f11c25">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a>coln, rown<span class="op">=</span>LevelP.shape</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"row:</span><span class="sc">{</span>rown<span class="sc">}</span><span class="ss"> col:</span><span class="sc">{</span>coln<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>row:224 col:15</code></pre>
</div>
</div>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a>Приведем данные массива к строковому виду</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div class="cell" data-executioninfo="{&quot;elapsed&quot;:1042,&quot;status&quot;:&quot;ok&quot;,&quot;timestamp&quot;:1673065118565,&quot;user&quot;:{&quot;displayName&quot;:&quot;Vladimir Orlenko&quot;,&quot;userId&quot;:&quot;14647639487768811794&quot;},&quot;user_tz&quot;:-360}" data-outputid="5129ca6a-c91f-4b1b-bf56-ccee4c622f53">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a>raw_text<span class="op">=</span><span class="st">""</span></span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(rown):</span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> j <span class="kw">in</span> <span class="bu">range</span>(coln):</span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a>    raw_text<span class="op">=</span>raw_text<span class="op">+</span>LevelP[j,rown<span class="op">-</span>i<span class="op">-</span><span class="dv">1</span>].decode(<span class="st">'UTF-8'</span>)</span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a>  raw_text<span class="op">=</span>raw_text<span class="op">+</span><span class="st">'</span><span class="ch">\n</span><span class="st">'</span></span>
<span id="cb8-7"><a href="#cb8-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-8"><a href="#cb8-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(raw_text)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>-------------GG
-------------GG
-------------GG
-------------GG
-------------GG
-------------GG
-------------GG
-------------GG
-------------GG
-------------GG
-------------GG
-------------GG
-------------GG
-------------GG
-------------GG
-------------GG
---------?---GG
-------------GG
-------------GG
-------------GG
---------=---GG
-------------GG
-----?---=---GG
---------?---GG
---------=---GG
-------------GG
-------------GG
-------------GG
-----------PPGG
-----------PPGG
-------------GG
-------------GG
-------------GG
-------------GG
-------------GG
-------------GG
-------------GG
-------------GG
----------PPPGG
----------PPPGG
-------------GG
-------------GG
-------------GG
-------------GG
-------------GG
-------------GG
---------PPPPGG
---------PPPPGG
-------------GG
-------------GG
-------------GG
-------------GG
-------------GG
-------------GG
-------------GG
-------------GG
-------------GG
---------PPPPGG
---------PPPPGG
-------------GG
-------------GG
-------------GG
-------------GG
-------------GG
-------------GG
-------------GG
-------------GG
-------------GG
-------------GG
---------------
---------------
-------------GG
-------------GG
-------------GG
-------------GG
-------------GG
-------------GG
---------=---GG
---------?---GG
---------=---GG
-----=-------GG
-----=-------GG
-----=-------GG
-----=-------GG
-----=-------GG
-----=-------GG
-----=---------
-----=---------
---------------
-------------GG
-------------GG
-----=-------GG
-----=-------GG
-----=-------GG
-----?---=---GG
-------------GG
-------------GG
-------------GG
-------------GG
-------------GG
---------=---GG
---------=---GG
-------------GG
-------------GG
-------------GG
-------------GG
---------?---GG
-------------GG
-------------GG
-----?---?---GG
-------------GG
-------------GG
---------?---GG
-------------GG
-------------GG
-------------GG
-------------GG
-------------GG
---------=---GG
-------------GG
-------------GG
-----=-------GG
-----=-------GG
-----=-------GG
-------------GG
-------------GG
-------------GG
-------------GG
-----=-------GG
-----?---=---GG
-----?---=---GG
-----=-------GG
-------------GG
-------------GG
------------#GG
-----------##GG
----------###GG
---------####GG
-------------GG
-------------GG
---------####GG
----------###GG
-----------##GG
------------#GG
-------------GG
-------------GG
-------------GG
-------------GG
------------#GG
-----------##GG
----------###GG
---------####GG
---------####GG
---------------
---------------
---------####GG
----------###GG
-----------##GG
------------#GG
-------------GG
-------------GG
-------------GG
-------------GG
-----------PPGG
-----------PPGG
-------------GG
-------------GG
-------------GG
---------=---GG
---------=---GG
---------?---GG
---------=---GG
-------------GG
-------------GG
-------------GG
-------------GG
-------------GG
-------------GG
-------------GG
-----------PPGG
-----------PPGG
------------#GG
-----------##GG
----------###GG
---------####GG
--------#####GG
-------######GG
------#######GG
-----########GG
-----########GG
-------------GG
-------------GG
-------------GG
-------------GG
-------------GG
-------------GG
-------------GG
-------------GG
---|||||||||#GG
-------------GG
-------------GG
-------------GG
----------\SSGG
--------\C\SSGG
--------\S\UOGG
--------\D\SSGG
----------\SSGG
-------------GG
-------------GG
-------------GG
-------------GG
-------------GG
-------------GG
-------------GG
-------------GG
-------------GG
-------------GG
-------------GG
-------------GG
-------------GG
-------------GG
-------------GG
-------------GG
-------------GG
</code></pre>
</div>
</div>
<p>Теперь можно приступать к сборке и обучению модели</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="co"># create mapping of unique chars to integers</span></span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a>chars <span class="op">=</span> <span class="bu">sorted</span>(<span class="bu">list</span>(<span class="bu">set</span>(raw_text)))</span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a>char_to_int <span class="op">=</span> <span class="bu">dict</span>((c, i) <span class="cf">for</span> i, c <span class="kw">in</span> <span class="bu">enumerate</span>(chars))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div class="cell" data-executioninfo="{&quot;elapsed&quot;:3,&quot;status&quot;:&quot;ok&quot;,&quot;timestamp&quot;:1673065140138,&quot;user&quot;:{&quot;displayName&quot;:&quot;Vladimir Orlenko&quot;,&quot;userId&quot;:&quot;14647639487768811794&quot;},&quot;user_tz&quot;:-360}" data-outputid="8531dd18-9291-47a2-f61c-87daa6fa684d">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a>n_chars <span class="op">=</span> <span class="bu">len</span>(raw_text)</span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a>n_vocab <span class="op">=</span> <span class="bu">len</span>(chars)</span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span> (<span class="ss">f"Total Characters: </span><span class="sc">{</span>n_chars<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span> (<span class="ss">f"Total Vocab: </span><span class="sc">{</span>n_vocab<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Total Characters: 3584
Total Vocab: 14</code></pre>
</div>
</div>
<p>Мы видим, что набор содержит более 3000 символов и что при преобразовании в словаре есть только 14 различных символов для изучения сетью. Гораздо меньше, чем 32 в алфавите.</p>
<p>Теперь нам нужно определить данные обучения для сети. Есть множество вариантов по разбиению текста и подаче его в сеть во время обучения.</p>
<p>На этом этапе мы разделим текст на подпоследовательности с фиксированной длиной в 160 символов.</p>
<p>Каждый обучающий шаблон сети состоит из 160 временных шагов одного символа (X), за которыми следует один символьный вывод (y). При создании этих последовательностей мы перемещаем это окно по всей книге по одному символу за раз, позволяя каждому символу получить шанс из 160 предшествующих ему символов (кроме, конечно, первых 160 символов).</p>
<div class="cell" data-executioninfo="{&quot;elapsed&quot;:589,&quot;status&quot;:&quot;ok&quot;,&quot;timestamp&quot;:1673065150593,&quot;user&quot;:{&quot;displayName&quot;:&quot;Vladimir Orlenko&quot;,&quot;userId&quot;:&quot;14647639487768811794&quot;},&quot;user_tz&quot;:-360}" data-outputid="6a6726c3-a6ba-4382-cb25-d16912667dde">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="co"># prepare the dataset of input to output pairs encoded as integers</span></span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a>seq_length <span class="op">=</span> <span class="dv">160</span></span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a>dataX <span class="op">=</span> []</span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a>dataY <span class="op">=</span> []</span>
<span id="cb13-5"><a href="#cb13-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-6"><a href="#cb13-6" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">0</span>, n_chars <span class="op">-</span> seq_length, <span class="dv">1</span>):</span>
<span id="cb13-7"><a href="#cb13-7" aria-hidden="true" tabindex="-1"></a>    seq_in <span class="op">=</span> raw_text[i:i <span class="op">+</span> seq_length]</span>
<span id="cb13-8"><a href="#cb13-8" aria-hidden="true" tabindex="-1"></a>    seq_out <span class="op">=</span> raw_text[i <span class="op">+</span> seq_length]</span>
<span id="cb13-9"><a href="#cb13-9" aria-hidden="true" tabindex="-1"></a>    dataX.append([char_to_int[char] <span class="cf">for</span> char <span class="kw">in</span> seq_in])</span>
<span id="cb13-10"><a href="#cb13-10" aria-hidden="true" tabindex="-1"></a>    dataY.append(char_to_int[seq_out])</span>
<span id="cb13-11"><a href="#cb13-11" aria-hidden="true" tabindex="-1"></a>n_patterns <span class="op">=</span> <span class="bu">len</span>(dataX)</span>
<span id="cb13-12"><a href="#cb13-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-13"><a href="#cb13-13" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span> (<span class="ss">f"Total Patterns: </span><span class="sc">{</span>n_patterns<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Total Patterns: 3424</code></pre>
</div>
</div>
<p>Теперь, когда мы подготовили наши тренировочные данные, нам нужно преобразовать их так, чтобы они подходили для использования с Keras.</p>
<p>Сначала мы должны преобразовать список входных последовательностей в форму[образцы, временные шаги, особенности]ожидается сетью LSTM.</p>
<p>Затем нам нужно изменить масштаб целых чисел в диапазоне от 0 до 1, чтобы облегчить изучение шаблонов сетью LSTM, которая по умолчанию использует функцию активации сигмовидной кишки.</p>
<p>Наконец, нам нужно преобразовать выходные шаблоны (отдельные символы, преобразованные в целые числа) в одну горячую кодировку. Это сделано для того, чтобы мы могли настроить сеть так, чтобы она предсказывала вероятность каждого из 14 различных символов в словаре (более простое представление), а не пыталась заставить ее предсказать точно следующий символ. Каждое значение y преобразуется в разреженный вектор длиной 14, полный нулей, за исключением 1 в столбце для буквы (целое число), которую представляет шаблон.</p>
<p>Мы можем реализовать эти шаги, как показано ниже.</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> keras.utils <span class="im">import</span> np_utils</span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a><span class="co"># reshape X to be [samples, time steps, features]</span></span>
<span id="cb15-4"><a href="#cb15-4" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> np.reshape(dataX, (n_patterns, seq_length, <span class="dv">1</span>))</span>
<span id="cb15-5"><a href="#cb15-5" aria-hidden="true" tabindex="-1"></a><span class="co"># normalize</span></span>
<span id="cb15-6"><a href="#cb15-6" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> X <span class="op">/</span> <span class="bu">float</span>(n_vocab)</span>
<span id="cb15-7"><a href="#cb15-7" aria-hidden="true" tabindex="-1"></a><span class="co"># one hot encode the output variable</span></span>
<span id="cb15-8"><a href="#cb15-8" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> np_utils.to_categorical(dataY)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> keras.models <span class="im">import</span> Sequential</span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> keras.layers <span class="im">import</span> Dense</span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> keras.layers <span class="im">import</span> Dropout</span>
<span id="cb16-4"><a href="#cb16-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> keras.layers <span class="im">import</span> LSTM</span>
<span id="cb16-5"><a href="#cb16-5" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> keras.callbacks <span class="im">import</span> ModelCheckpoint</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div class="cell" data-executioninfo="{&quot;elapsed&quot;:334,&quot;status&quot;:&quot;ok&quot;,&quot;timestamp&quot;:1673024789570,&quot;user&quot;:{&quot;displayName&quot;:&quot;Vladimir Orlenko&quot;,&quot;userId&quot;:&quot;14647639487768811794&quot;},&quot;user_tz&quot;:-360}" data-outputid="7657aecf-3881-40f2-f1c6-22874ba51306">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a>y.shape[<span class="dv">1</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="179">
<pre><code>14</code></pre>
</div>
</div>
<p>Теперь мы можем определить нашу модель LSTM. Здесь мы определяем один скрытый слой LSTM с 256 единицами памяти. Сеть использует выпадение с вероятностью 20. Выходной уровень - это Плотный уровень, использующий функцию активации softmax для вывода прогнозирования вероятности для каждого из 14 символов в диапазоне от 0 до 1.</p>
<p>Эта проблема на самом деле представляет собой проблему классификации отдельных символов с 14 классами, и поэтому она определяется как оптимизация потерь в журнале (перекрестная энтропия) с использованием алгоритма оптимизации ADAM по скорости.</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb19"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a><span class="co"># define the LSTM model</span></span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> Sequential()</span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true" tabindex="-1"></a>model.add(LSTM(<span class="dv">256</span>, input_shape<span class="op">=</span>(X.shape[<span class="dv">1</span>], X.shape[<span class="dv">2</span>])))</span>
<span id="cb19-4"><a href="#cb19-4" aria-hidden="true" tabindex="-1"></a>model.add(Dropout(<span class="fl">0.2</span>))</span>
<span id="cb19-5"><a href="#cb19-5" aria-hidden="true" tabindex="-1"></a>model.add(Dense(y.shape[<span class="dv">1</span>], activation<span class="op">=</span><span class="st">'softmax'</span>))</span>
<span id="cb19-6"><a href="#cb19-6" aria-hidden="true" tabindex="-1"></a>model.<span class="bu">compile</span>(loss<span class="op">=</span><span class="st">'categorical_crossentropy'</span>, optimizer<span class="op">=</span><span class="st">'adam'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>Тестового набора данных нет. Мы моделируем весь обучающий набор данных, чтобы узнать вероятность каждого персонажа в последовательности.</p>
<p>Нас не интересует наиболее точная (точность классификации) модель учебного набора данных. Это будет модель, которая идеально предсказывает каждого символа в наборе обучающих данных. Вместо этого мы заинтересованы в обобщении набора данных, который минимизирует выбранную функцию потерь. Мы ищем баланс между обобщением и переобучением, но без запоминания.</p>
<p>Сеть работает медленно (около 300 секунд на эпоху на графическом процессоре Nvidia K520). Из-за медлительности и из-за наших требований по оптимизации мы будем использовать контрольные точки модели для записи всех сетевых весов, чтобы каждый раз регистрировать улучшение потерь в конце эпохи. Мы будем использовать лучший набор весов (наименьшая потеря), чтобы реализовать нашу генеративную модель в следующем разделе.</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb20"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a><span class="co"># define the checkpoint</span></span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a>filepath<span class="op">=</span><span class="st">"/content/drive/MyDrive/Проекты/ML/Pets/rnn_mario_level_builder/data/weights-improvement-</span><span class="sc">{epoch:02d}</span><span class="st">-</span><span class="sc">{loss:.4f}</span><span class="st">.hdf5"</span></span>
<span id="cb20-3"><a href="#cb20-3" aria-hidden="true" tabindex="-1"></a>checkpoint <span class="op">=</span> ModelCheckpoint(filepath, monitor<span class="op">=</span><span class="st">'loss'</span>, verbose<span class="op">=</span><span class="dv">1</span>, save_best_only<span class="op">=</span><span class="va">True</span>, mode<span class="op">=</span><span class="st">'min'</span>)</span>
<span id="cb20-4"><a href="#cb20-4" aria-hidden="true" tabindex="-1"></a>callbacks_list <span class="op">=</span> [checkpoint]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>Теперь мы можем приспособить нашу модель к данным. Здесь мы используем скромное количество из 100 эпох и большой размер пакета из 128 шаблонов.</p>
<div class="cell" data-executioninfo="{&quot;elapsed&quot;:623760,&quot;status&quot;:&quot;ok&quot;,&quot;timestamp&quot;:1673070049748,&quot;user&quot;:{&quot;displayName&quot;:&quot;Vladimir Orlenko&quot;,&quot;userId&quot;:&quot;14647639487768811794&quot;},&quot;user_tz&quot;:-360}" data-outputid="607a7a4c-2421-4251-b632-888a4f2d3279">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb21"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a>history<span class="op">=</span>model.fit(X, y, epochs<span class="op">=</span><span class="dv">1000</span>, batch_size<span class="op">=</span><span class="dv">128</span>, callbacks<span class="op">=</span>callbacks_list)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Epoch 1/1000
27/27 [==============================] - ETA: 0s - loss: 0.0184
Epoch 1: loss did not improve from 0.00715
27/27 [==============================] - 2s 25ms/step - loss: 0.0184
Epoch 2/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0220
Epoch 2: loss did not improve from 0.00715
27/27 [==============================] - 1s 20ms/step - loss: 0.0221
Epoch 3/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0113
Epoch 3: loss did not improve from 0.00715
27/27 [==============================] - 1s 20ms/step - loss: 0.0116
Epoch 4/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0127
Epoch 4: loss did not improve from 0.00715
27/27 [==============================] - 1s 20ms/step - loss: 0.0120
Epoch 5/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0108
Epoch 5: loss did not improve from 0.00715
27/27 [==============================] - 1s 20ms/step - loss: 0.0103
Epoch 6/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0123
Epoch 6: loss did not improve from 0.00715
27/27 [==============================] - 1s 20ms/step - loss: 0.0118
Epoch 7/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0139
Epoch 7: loss did not improve from 0.00715
27/27 [==============================] - 1s 20ms/step - loss: 0.0138
Epoch 8/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0143
Epoch 8: loss did not improve from 0.00715
27/27 [==============================] - 1s 20ms/step - loss: 0.0147
Epoch 9/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0170
Epoch 9: loss did not improve from 0.00715
27/27 [==============================] - 1s 20ms/step - loss: 0.0164
Epoch 10/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0125
Epoch 10: loss did not improve from 0.00715
27/27 [==============================] - 1s 20ms/step - loss: 0.0125
Epoch 11/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0120
Epoch 11: loss did not improve from 0.00715
27/27 [==============================] - 1s 20ms/step - loss: 0.0124
Epoch 12/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0117
Epoch 12: loss did not improve from 0.00715
27/27 [==============================] - 1s 19ms/step - loss: 0.0133
Epoch 13/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0190
Epoch 13: loss did not improve from 0.00715
27/27 [==============================] - 1s 20ms/step - loss: 0.0182
Epoch 14/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0140
Epoch 14: loss did not improve from 0.00715
27/27 [==============================] - 1s 20ms/step - loss: 0.0167
Epoch 15/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0295
Epoch 15: loss did not improve from 0.00715
27/27 [==============================] - 1s 20ms/step - loss: 0.0278
Epoch 16/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0225
Epoch 16: loss did not improve from 0.00715
27/27 [==============================] - 1s 20ms/step - loss: 0.0228
Epoch 17/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0195
Epoch 17: loss did not improve from 0.00715
27/27 [==============================] - 1s 20ms/step - loss: 0.0192
Epoch 18/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0188
Epoch 18: loss did not improve from 0.00715
27/27 [==============================] - 1s 20ms/step - loss: 0.0203
Epoch 19/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0135
Epoch 19: loss did not improve from 0.00715
27/27 [==============================] - 1s 20ms/step - loss: 0.0128
Epoch 20/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0250
Epoch 20: loss did not improve from 0.00715
27/27 [==============================] - 1s 20ms/step - loss: 0.0236
Epoch 21/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0162
Epoch 21: loss did not improve from 0.00715
27/27 [==============================] - 1s 20ms/step - loss: 0.0162
Epoch 22/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0138
Epoch 22: loss did not improve from 0.00715
27/27 [==============================] - 1s 20ms/step - loss: 0.0137
Epoch 23/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0118
Epoch 23: loss did not improve from 0.00715
27/27 [==============================] - 1s 20ms/step - loss: 0.0122
Epoch 24/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0139
Epoch 24: loss did not improve from 0.00715
27/27 [==============================] - 1s 20ms/step - loss: 0.0131
Epoch 25/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0106
Epoch 25: loss did not improve from 0.00715
27/27 [==============================] - 1s 20ms/step - loss: 0.0101
Epoch 26/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0096
Epoch 26: loss did not improve from 0.00715
27/27 [==============================] - 1s 20ms/step - loss: 0.0091
Epoch 27/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0079
Epoch 27: loss did not improve from 0.00715
27/27 [==============================] - 1s 20ms/step - loss: 0.0075
Epoch 28/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0087
Epoch 28: loss did not improve from 0.00715
27/27 [==============================] - 1s 20ms/step - loss: 0.0082
Epoch 29/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0091
Epoch 29: loss did not improve from 0.00715
27/27 [==============================] - 1s 20ms/step - loss: 0.0088
Epoch 30/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0085
Epoch 30: loss did not improve from 0.00715
27/27 [==============================] - 1s 20ms/step - loss: 0.0081
Epoch 31/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0082
Epoch 31: loss did not improve from 0.00715
27/27 [==============================] - 1s 20ms/step - loss: 0.0081
Epoch 32/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0074
Epoch 32: loss improved from 0.00715 to 0.00705, saving model to /content/drive/MyDrive/Проекты/ML/Pets/rnn_mario_level_builder/data/weights-improvement-32-0.0070.hdf5
27/27 [==============================] - 1s 22ms/step - loss: 0.0070
Epoch 33/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0077
Epoch 33: loss did not improve from 0.00705
27/27 [==============================] - 1s 20ms/step - loss: 0.0074
Epoch 34/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0073
Epoch 34: loss did not improve from 0.00705
27/27 [==============================] - 1s 20ms/step - loss: 0.0111
Epoch 35/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0127
Epoch 35: loss did not improve from 0.00705
27/27 [==============================] - 1s 20ms/step - loss: 0.0123
Epoch 36/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0118
Epoch 36: loss did not improve from 0.00705
27/27 [==============================] - 1s 20ms/step - loss: 0.0113
Epoch 37/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0079
Epoch 37: loss did not improve from 0.00705
27/27 [==============================] - 1s 20ms/step - loss: 0.0096
Epoch 38/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0091
Epoch 38: loss did not improve from 0.00705
27/27 [==============================] - 1s 20ms/step - loss: 0.0086
Epoch 39/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0079
Epoch 39: loss did not improve from 0.00705
27/27 [==============================] - 1s 20ms/step - loss: 0.0076
Epoch 40/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0105
Epoch 40: loss did not improve from 0.00705
27/27 [==============================] - 1s 20ms/step - loss: 0.0102
Epoch 41/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0161
Epoch 41: loss did not improve from 0.00705
27/27 [==============================] - 1s 20ms/step - loss: 0.0153
Epoch 42/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0189
Epoch 42: loss did not improve from 0.00705
27/27 [==============================] - 1s 20ms/step - loss: 0.0181
Epoch 43/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0198
Epoch 43: loss did not improve from 0.00705
27/27 [==============================] - 1s 20ms/step - loss: 0.0209
Epoch 44/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0390
Epoch 44: loss did not improve from 0.00705
27/27 [==============================] - 1s 20ms/step - loss: 0.0392
Epoch 45/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0277
Epoch 45: loss did not improve from 0.00705
27/27 [==============================] - 1s 20ms/step - loss: 0.0272
Epoch 46/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0199
Epoch 46: loss did not improve from 0.00705
27/27 [==============================] - 1s 20ms/step - loss: 0.0192
Epoch 47/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0151
Epoch 47: loss did not improve from 0.00705
27/27 [==============================] - 1s 20ms/step - loss: 0.0144
Epoch 48/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0127
Epoch 48: loss did not improve from 0.00705
27/27 [==============================] - 1s 20ms/step - loss: 0.0136
Epoch 49/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0141
Epoch 49: loss did not improve from 0.00705
27/27 [==============================] - 1s 20ms/step - loss: 0.0164
Epoch 50/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0184
Epoch 50: loss did not improve from 0.00705
27/27 [==============================] - 1s 20ms/step - loss: 0.0175
Epoch 51/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0166
Epoch 51: loss did not improve from 0.00705
27/27 [==============================] - 1s 20ms/step - loss: 0.0169
Epoch 52/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0118
Epoch 52: loss did not improve from 0.00705
27/27 [==============================] - 1s 20ms/step - loss: 0.0114
Epoch 53/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0093
Epoch 53: loss did not improve from 0.00705
27/27 [==============================] - 1s 20ms/step - loss: 0.0090
Epoch 54/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0089
Epoch 54: loss did not improve from 0.00705
27/27 [==============================] - 1s 21ms/step - loss: 0.0087
Epoch 55/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0135
Epoch 55: loss did not improve from 0.00705
27/27 [==============================] - 1s 20ms/step - loss: 0.0185
Epoch 56/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0325
Epoch 56: loss did not improve from 0.00705
27/27 [==============================] - 1s 20ms/step - loss: 0.0336
Epoch 57/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0435
Epoch 57: loss did not improve from 0.00705
27/27 [==============================] - 1s 20ms/step - loss: 0.0441
Epoch 58/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0248
Epoch 58: loss did not improve from 0.00705
27/27 [==============================] - 1s 21ms/step - loss: 0.0236
Epoch 59/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0133
Epoch 59: loss did not improve from 0.00705
27/27 [==============================] - 1s 20ms/step - loss: 0.0147
Epoch 60/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0135
Epoch 60: loss did not improve from 0.00705
27/27 [==============================] - 1s 21ms/step - loss: 0.0129
Epoch 61/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0162
Epoch 61: loss did not improve from 0.00705
27/27 [==============================] - 1s 20ms/step - loss: 0.0159
Epoch 62/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0165
Epoch 62: loss did not improve from 0.00705
27/27 [==============================] - 1s 21ms/step - loss: 0.0170
Epoch 63/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0114
Epoch 63: loss did not improve from 0.00705
27/27 [==============================] - 1s 20ms/step - loss: 0.0131
Epoch 64/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0107
Epoch 64: loss did not improve from 0.00705
27/27 [==============================] - 1s 20ms/step - loss: 0.0114
Epoch 65/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0077
Epoch 65: loss did not improve from 0.00705
27/27 [==============================] - 1s 20ms/step - loss: 0.0087
Epoch 66/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0119
Epoch 66: loss did not improve from 0.00705
27/27 [==============================] - 1s 21ms/step - loss: 0.0116
Epoch 67/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0165
Epoch 67: loss did not improve from 0.00705
27/27 [==============================] - 1s 21ms/step - loss: 0.0164
Epoch 68/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0164
Epoch 68: loss did not improve from 0.00705
27/27 [==============================] - 1s 21ms/step - loss: 0.0165
Epoch 69/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0224
Epoch 69: loss did not improve from 0.00705
27/27 [==============================] - 1s 21ms/step - loss: 0.0213
Epoch 70/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0267
Epoch 70: loss did not improve from 0.00705
27/27 [==============================] - 1s 20ms/step - loss: 0.0337
Epoch 71/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.1082
Epoch 71: loss did not improve from 0.00705
27/27 [==============================] - 1s 20ms/step - loss: 0.1063
Epoch 72/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0563
Epoch 72: loss did not improve from 0.00705
27/27 [==============================] - 1s 20ms/step - loss: 0.0537
Epoch 73/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0260
Epoch 73: loss did not improve from 0.00705
27/27 [==============================] - 1s 20ms/step - loss: 0.0248
Epoch 74/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0184
Epoch 74: loss did not improve from 0.00705
27/27 [==============================] - 1s 21ms/step - loss: 0.0186
Epoch 75/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0120
Epoch 75: loss did not improve from 0.00705
27/27 [==============================] - 1s 21ms/step - loss: 0.0138
Epoch 76/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0120
Epoch 76: loss did not improve from 0.00705
27/27 [==============================] - 1s 20ms/step - loss: 0.0118
Epoch 77/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0107
Epoch 77: loss did not improve from 0.00705
27/27 [==============================] - 1s 21ms/step - loss: 0.0107
Epoch 78/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0096
Epoch 78: loss did not improve from 0.00705
27/27 [==============================] - 1s 20ms/step - loss: 0.0092
Epoch 79/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0110
Epoch 79: loss did not improve from 0.00705
27/27 [==============================] - 1s 20ms/step - loss: 0.0105
Epoch 80/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0096
Epoch 80: loss did not improve from 0.00705
27/27 [==============================] - 1s 21ms/step - loss: 0.0099
Epoch 81/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0101
Epoch 81: loss did not improve from 0.00705
27/27 [==============================] - 1s 21ms/step - loss: 0.0098
Epoch 82/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0153
Epoch 82: loss did not improve from 0.00705
27/27 [==============================] - 1s 21ms/step - loss: 0.0154
Epoch 83/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0127
Epoch 83: loss did not improve from 0.00705
27/27 [==============================] - 1s 20ms/step - loss: 0.0149
Epoch 84/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0404
Epoch 84: loss did not improve from 0.00705
27/27 [==============================] - 1s 21ms/step - loss: 0.0388
Epoch 85/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0191
Epoch 85: loss did not improve from 0.00705
27/27 [==============================] - 1s 21ms/step - loss: 0.0183
Epoch 86/1000
27/27 [==============================] - ETA: 0s - loss: 0.0124
Epoch 86: loss did not improve from 0.00705
27/27 [==============================] - 1s 21ms/step - loss: 0.0124
Epoch 87/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0072
Epoch 87: loss did not improve from 0.00705
27/27 [==============================] - 1s 21ms/step - loss: 0.0102
Epoch 88/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0080
Epoch 88: loss did not improve from 0.00705
27/27 [==============================] - 1s 20ms/step - loss: 0.0077
Epoch 89/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0086
Epoch 89: loss did not improve from 0.00705
27/27 [==============================] - 1s 21ms/step - loss: 0.0082
Epoch 90/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0080
Epoch 90: loss did not improve from 0.00705
27/27 [==============================] - 1s 21ms/step - loss: 0.0075
Epoch 91/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0086
Epoch 91: loss did not improve from 0.00705
27/27 [==============================] - 1s 21ms/step - loss: 0.0081
Epoch 92/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0093
Epoch 92: loss did not improve from 0.00705
27/27 [==============================] - 1s 21ms/step - loss: 0.0088
Epoch 93/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0097
Epoch 93: loss did not improve from 0.00705
27/27 [==============================] - 1s 21ms/step - loss: 0.0091
Epoch 94/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0080
Epoch 94: loss did not improve from 0.00705
27/27 [==============================] - 1s 21ms/step - loss: 0.0081
Epoch 95/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0220
Epoch 95: loss did not improve from 0.00705
27/27 [==============================] - 1s 21ms/step - loss: 0.0220
Epoch 96/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0277
Epoch 96: loss did not improve from 0.00705
27/27 [==============================] - 1s 21ms/step - loss: 0.0264
Epoch 97/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0136
Epoch 97: loss did not improve from 0.00705
27/27 [==============================] - 1s 21ms/step - loss: 0.0130
Epoch 98/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0148
Epoch 98: loss did not improve from 0.00705
27/27 [==============================] - 1s 21ms/step - loss: 0.0153
Epoch 99/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0102
Epoch 99: loss did not improve from 0.00705
27/27 [==============================] - 1s 20ms/step - loss: 0.0118
Epoch 100/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0100
Epoch 100: loss did not improve from 0.00705
27/27 [==============================] - 1s 21ms/step - loss: 0.0099
Epoch 101/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0081
Epoch 101: loss did not improve from 0.00705
27/27 [==============================] - 1s 21ms/step - loss: 0.0083
Epoch 102/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0068
Epoch 102: loss improved from 0.00705 to 0.00696, saving model to /content/drive/MyDrive/Проекты/ML/Pets/rnn_mario_level_builder/data/weights-improvement-102-0.0070.hdf5
27/27 [==============================] - 1s 22ms/step - loss: 0.0070
Epoch 103/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0073
Epoch 103: loss did not improve from 0.00696
27/27 [==============================] - 1s 21ms/step - loss: 0.0070
Epoch 104/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0069
Epoch 104: loss improved from 0.00696 to 0.00688, saving model to /content/drive/MyDrive/Проекты/ML/Pets/rnn_mario_level_builder/data/weights-improvement-104-0.0069.hdf5
27/27 [==============================] - 1s 22ms/step - loss: 0.0069
Epoch 105/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0071
Epoch 105: loss improved from 0.00688 to 0.00671, saving model to /content/drive/MyDrive/Проекты/ML/Pets/rnn_mario_level_builder/data/weights-improvement-105-0.0067.hdf5
27/27 [==============================] - 1s 23ms/step - loss: 0.0067
Epoch 106/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0056
Epoch 106: loss improved from 0.00671 to 0.00553, saving model to /content/drive/MyDrive/Проекты/ML/Pets/rnn_mario_level_builder/data/weights-improvement-106-0.0055.hdf5
27/27 [==============================] - 1s 22ms/step - loss: 0.0055
Epoch 107/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0069
Epoch 107: loss did not improve from 0.00553
27/27 [==============================] - 1s 21ms/step - loss: 0.0067
Epoch 108/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0058
Epoch 108: loss did not improve from 0.00553
27/27 [==============================] - 1s 21ms/step - loss: 0.0061
Epoch 109/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0060
Epoch 109: loss did not improve from 0.00553
27/27 [==============================] - 1s 21ms/step - loss: 0.0074
Epoch 110/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0056
Epoch 110: loss improved from 0.00553 to 0.00551, saving model to /content/drive/MyDrive/Проекты/ML/Pets/rnn_mario_level_builder/data/weights-improvement-110-0.0055.hdf5
27/27 [==============================] - 1s 22ms/step - loss: 0.0055
Epoch 111/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0059
Epoch 111: loss did not improve from 0.00551
27/27 [==============================] - 1s 21ms/step - loss: 0.0056
Epoch 112/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0044
Epoch 112: loss did not improve from 0.00551
27/27 [==============================] - 1s 21ms/step - loss: 0.0055
Epoch 113/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0099
Epoch 113: loss did not improve from 0.00551
27/27 [==============================] - 1s 21ms/step - loss: 0.0095
Epoch 114/1000
26/27 [===========================&gt;..] - ETA: 0s - loss: 0.0140
Epoch 114: loss did not improve from 0.00551
27/27 [==============================] - 1s 22ms/step - loss: 0.0139
Epoch 115/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0413
Epoch 115: loss did not improve from 0.00551
27/27 [==============================] - 1s 21ms/step - loss: 0.0436
Epoch 116/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0317
Epoch 116: loss did not improve from 0.00551
27/27 [==============================] - 1s 21ms/step - loss: 0.0302
Epoch 117/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0165
Epoch 117: loss did not improve from 0.00551
27/27 [==============================] - 1s 21ms/step - loss: 0.0167
Epoch 118/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0134
Epoch 118: loss did not improve from 0.00551
27/27 [==============================] - 1s 21ms/step - loss: 0.0131
Epoch 119/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0104
Epoch 119: loss did not improve from 0.00551
27/27 [==============================] - 1s 21ms/step - loss: 0.0103
Epoch 120/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0075
Epoch 120: loss did not improve from 0.00551
27/27 [==============================] - 1s 21ms/step - loss: 0.0088
Epoch 121/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0086
Epoch 121: loss did not improve from 0.00551
27/27 [==============================] - 1s 21ms/step - loss: 0.0082
Epoch 122/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0099
Epoch 122: loss did not improve from 0.00551
27/27 [==============================] - 1s 21ms/step - loss: 0.0097
Epoch 123/1000
27/27 [==============================] - ETA: 0s - loss: 0.0723
Epoch 123: loss did not improve from 0.00551
27/27 [==============================] - 1s 21ms/step - loss: 0.0723
Epoch 124/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0734
Epoch 124: loss did not improve from 0.00551
27/27 [==============================] - 1s 21ms/step - loss: 0.0725
Epoch 125/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0431
Epoch 125: loss did not improve from 0.00551
27/27 [==============================] - 1s 21ms/step - loss: 0.0480
Epoch 126/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0287
Epoch 126: loss did not improve from 0.00551
27/27 [==============================] - 1s 21ms/step - loss: 0.0279
Epoch 127/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0202
Epoch 127: loss did not improve from 0.00551
27/27 [==============================] - 1s 21ms/step - loss: 0.0196
Epoch 128/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0167
Epoch 128: loss did not improve from 0.00551
27/27 [==============================] - 1s 21ms/step - loss: 0.0294
Epoch 129/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0733
Epoch 129: loss did not improve from 0.00551
27/27 [==============================] - 1s 21ms/step - loss: 0.0725
Epoch 130/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0295
Epoch 130: loss did not improve from 0.00551
27/27 [==============================] - 1s 21ms/step - loss: 0.0296
Epoch 131/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0193
Epoch 131: loss did not improve from 0.00551
27/27 [==============================] - 1s 21ms/step - loss: 0.0187
Epoch 132/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0163
Epoch 132: loss did not improve from 0.00551
27/27 [==============================] - 1s 21ms/step - loss: 0.0155
Epoch 133/1000
27/27 [==============================] - ETA: 0s - loss: 0.0114
Epoch 133: loss did not improve from 0.00551
27/27 [==============================] - 1s 21ms/step - loss: 0.0114
Epoch 134/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0133
Epoch 134: loss did not improve from 0.00551
27/27 [==============================] - 1s 21ms/step - loss: 0.0134
Epoch 135/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0108
Epoch 135: loss did not improve from 0.00551
27/27 [==============================] - 1s 22ms/step - loss: 0.0108
Epoch 136/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0086
Epoch 136: loss did not improve from 0.00551
27/27 [==============================] - 1s 21ms/step - loss: 0.0090
Epoch 137/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0092
Epoch 137: loss did not improve from 0.00551
27/27 [==============================] - 1s 21ms/step - loss: 0.0094
Epoch 138/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0077
Epoch 138: loss did not improve from 0.00551
27/27 [==============================] - 1s 21ms/step - loss: 0.0078
Epoch 139/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0072
Epoch 139: loss did not improve from 0.00551
27/27 [==============================] - 1s 21ms/step - loss: 0.0069
Epoch 140/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0075
Epoch 140: loss did not improve from 0.00551
27/27 [==============================] - 1s 21ms/step - loss: 0.0089
Epoch 141/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0084
Epoch 141: loss did not improve from 0.00551
27/27 [==============================] - 1s 21ms/step - loss: 0.0079
Epoch 142/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0061
Epoch 142: loss did not improve from 0.00551
27/27 [==============================] - 1s 21ms/step - loss: 0.0078
Epoch 143/1000
27/27 [==============================] - ETA: 0s - loss: 0.0075
Epoch 143: loss did not improve from 0.00551
27/27 [==============================] - 1s 21ms/step - loss: 0.0075
Epoch 144/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0080
Epoch 144: loss did not improve from 0.00551
27/27 [==============================] - 1s 21ms/step - loss: 0.0079
Epoch 145/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0069
Epoch 145: loss did not improve from 0.00551
27/27 [==============================] - 1s 21ms/step - loss: 0.0066
Epoch 146/1000
27/27 [==============================] - ETA: 0s - loss: 0.0065
Epoch 146: loss did not improve from 0.00551
27/27 [==============================] - 1s 21ms/step - loss: 0.0065
Epoch 147/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0064
Epoch 147: loss did not improve from 0.00551
27/27 [==============================] - 1s 21ms/step - loss: 0.0064
Epoch 148/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0075
Epoch 148: loss did not improve from 0.00551
27/27 [==============================] - 1s 21ms/step - loss: 0.0072
Epoch 149/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0046
Epoch 149: loss did not improve from 0.00551
27/27 [==============================] - 1s 21ms/step - loss: 0.0064
Epoch 150/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0050
Epoch 150: loss improved from 0.00551 to 0.00484, saving model to /content/drive/MyDrive/Проекты/ML/Pets/rnn_mario_level_builder/data/weights-improvement-150-0.0048.hdf5
27/27 [==============================] - 1s 22ms/step - loss: 0.0048
Epoch 151/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0065
Epoch 151: loss did not improve from 0.00484
27/27 [==============================] - 1s 21ms/step - loss: 0.0061
Epoch 152/1000
27/27 [==============================] - ETA: 0s - loss: 0.0057
Epoch 152: loss did not improve from 0.00484
27/27 [==============================] - 1s 21ms/step - loss: 0.0057
Epoch 153/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0052
Epoch 153: loss did not improve from 0.00484
27/27 [==============================] - 1s 21ms/step - loss: 0.0054
Epoch 154/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0062
Epoch 154: loss did not improve from 0.00484
27/27 [==============================] - 1s 21ms/step - loss: 0.0059
Epoch 155/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0077
Epoch 155: loss did not improve from 0.00484
27/27 [==============================] - 1s 21ms/step - loss: 0.0080
Epoch 156/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0202
Epoch 156: loss did not improve from 0.00484
27/27 [==============================] - 1s 21ms/step - loss: 0.0211
Epoch 157/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0249
Epoch 157: loss did not improve from 0.00484
27/27 [==============================] - 1s 21ms/step - loss: 0.0237
Epoch 158/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0283
Epoch 158: loss did not improve from 0.00484
27/27 [==============================] - 1s 21ms/step - loss: 0.0299
Epoch 159/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0144
Epoch 159: loss did not improve from 0.00484
27/27 [==============================] - 1s 21ms/step - loss: 0.0148
Epoch 160/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0130
Epoch 160: loss did not improve from 0.00484
27/27 [==============================] - 1s 21ms/step - loss: 0.0125
Epoch 161/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0072
Epoch 161: loss did not improve from 0.00484
27/27 [==============================] - 1s 21ms/step - loss: 0.0072
Epoch 162/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0074
Epoch 162: loss did not improve from 0.00484
27/27 [==============================] - 1s 21ms/step - loss: 0.0089
Epoch 163/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0071
Epoch 163: loss did not improve from 0.00484
27/27 [==============================] - 1s 21ms/step - loss: 0.0079
Epoch 164/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0077
Epoch 164: loss did not improve from 0.00484
27/27 [==============================] - 1s 21ms/step - loss: 0.0075
Epoch 165/1000
27/27 [==============================] - ETA: 0s - loss: 0.0071
Epoch 165: loss did not improve from 0.00484
27/27 [==============================] - 1s 21ms/step - loss: 0.0071
Epoch 166/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0056
Epoch 166: loss did not improve from 0.00484
27/27 [==============================] - 1s 21ms/step - loss: 0.0054
Epoch 167/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0053
Epoch 167: loss did not improve from 0.00484
27/27 [==============================] - 1s 21ms/step - loss: 0.0061
Epoch 168/1000
27/27 [==============================] - ETA: 0s - loss: 0.0064
Epoch 168: loss did not improve from 0.00484
27/27 [==============================] - 1s 22ms/step - loss: 0.0064
Epoch 169/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0057
Epoch 169: loss did not improve from 0.00484
27/27 [==============================] - 1s 21ms/step - loss: 0.0054
Epoch 170/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0056
Epoch 170: loss did not improve from 0.00484
27/27 [==============================] - 1s 21ms/step - loss: 0.0053
Epoch 171/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0048
Epoch 171: loss did not improve from 0.00484
27/27 [==============================] - 1s 21ms/step - loss: 0.0049
Epoch 172/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0051
Epoch 172: loss did not improve from 0.00484
27/27 [==============================] - 1s 21ms/step - loss: 0.0058
Epoch 173/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0044
Epoch 173: loss did not improve from 0.00484
27/27 [==============================] - 1s 20ms/step - loss: 0.0056
Epoch 174/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0048
Epoch 174: loss improved from 0.00484 to 0.00475, saving model to /content/drive/MyDrive/Проекты/ML/Pets/rnn_mario_level_builder/data/weights-improvement-174-0.0048.hdf5
27/27 [==============================] - 1s 22ms/step - loss: 0.0048
Epoch 175/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0055
Epoch 175: loss did not improve from 0.00475
27/27 [==============================] - 1s 21ms/step - loss: 0.0053
Epoch 176/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0046
Epoch 176: loss did not improve from 0.00475
27/27 [==============================] - 1s 21ms/step - loss: 0.0053
Epoch 177/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0118
Epoch 177: loss did not improve from 0.00475
27/27 [==============================] - 1s 21ms/step - loss: 0.0131
Epoch 178/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0085
Epoch 178: loss did not improve from 0.00475
27/27 [==============================] - 1s 21ms/step - loss: 0.0081
Epoch 179/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0145
Epoch 179: loss did not improve from 0.00475
27/27 [==============================] - 1s 21ms/step - loss: 0.0145
Epoch 180/1000
26/27 [===========================&gt;..] - ETA: 0s - loss: 0.0177
Epoch 180: loss did not improve from 0.00475
27/27 [==============================] - 1s 22ms/step - loss: 0.0181
Epoch 181/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0124
Epoch 181: loss did not improve from 0.00475
27/27 [==============================] - 1s 21ms/step - loss: 0.0127
Epoch 182/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0188
Epoch 182: loss did not improve from 0.00475
27/27 [==============================] - 1s 21ms/step - loss: 0.0179
Epoch 183/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0167
Epoch 183: loss did not improve from 0.00475
27/27 [==============================] - 1s 21ms/step - loss: 0.0191
Epoch 184/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0168
Epoch 184: loss did not improve from 0.00475
27/27 [==============================] - 1s 22ms/step - loss: 0.0179
Epoch 185/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0188
Epoch 185: loss did not improve from 0.00475
27/27 [==============================] - 1s 21ms/step - loss: 0.0180
Epoch 186/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0144
Epoch 186: loss did not improve from 0.00475
27/27 [==============================] - 1s 21ms/step - loss: 0.0136
Epoch 187/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0084
Epoch 187: loss did not improve from 0.00475
27/27 [==============================] - 1s 21ms/step - loss: 0.0081
Epoch 188/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0075
Epoch 188: loss did not improve from 0.00475
27/27 [==============================] - 1s 21ms/step - loss: 0.0072
Epoch 189/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0065
Epoch 189: loss did not improve from 0.00475
27/27 [==============================] - 1s 21ms/step - loss: 0.0063
Epoch 190/1000
27/27 [==============================] - ETA: 0s - loss: 0.0083
Epoch 190: loss did not improve from 0.00475
27/27 [==============================] - 1s 22ms/step - loss: 0.0083
Epoch 191/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0070
Epoch 191: loss did not improve from 0.00475
27/27 [==============================] - 1s 21ms/step - loss: 0.0077
Epoch 192/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0318
Epoch 192: loss did not improve from 0.00475
27/27 [==============================] - 1s 22ms/step - loss: 0.0367
Epoch 193/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0636
Epoch 193: loss did not improve from 0.00475
27/27 [==============================] - 1s 21ms/step - loss: 0.0627
Epoch 194/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0271
Epoch 194: loss did not improve from 0.00475
27/27 [==============================] - 1s 22ms/step - loss: 0.0278
Epoch 195/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0160
Epoch 195: loss did not improve from 0.00475
27/27 [==============================] - 1s 21ms/step - loss: 0.0172
Epoch 196/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0160
Epoch 196: loss did not improve from 0.00475
27/27 [==============================] - 1s 21ms/step - loss: 0.0153
Epoch 197/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0099
Epoch 197: loss did not improve from 0.00475
27/27 [==============================] - 1s 21ms/step - loss: 0.0111
Epoch 198/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0127
Epoch 198: loss did not improve from 0.00475
27/27 [==============================] - 1s 22ms/step - loss: 0.0128
Epoch 199/1000
27/27 [==============================] - ETA: 0s - loss: 0.0113
Epoch 199: loss did not improve from 0.00475
27/27 [==============================] - 1s 22ms/step - loss: 0.0113
Epoch 200/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0088
Epoch 200: loss did not improve from 0.00475
27/27 [==============================] - 1s 21ms/step - loss: 0.0083
Epoch 201/1000
27/27 [==============================] - ETA: 0s - loss: 0.0075
Epoch 201: loss did not improve from 0.00475
27/27 [==============================] - 1s 22ms/step - loss: 0.0075
Epoch 202/1000
27/27 [==============================] - ETA: 0s - loss: 0.0064
Epoch 202: loss did not improve from 0.00475
27/27 [==============================] - 1s 21ms/step - loss: 0.0064
Epoch 203/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0063
Epoch 203: loss did not improve from 0.00475
27/27 [==============================] - 1s 21ms/step - loss: 0.0060
Epoch 204/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0061
Epoch 204: loss did not improve from 0.00475
27/27 [==============================] - 1s 21ms/step - loss: 0.0058
Epoch 205/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0049
Epoch 205: loss did not improve from 0.00475
27/27 [==============================] - 1s 21ms/step - loss: 0.0049
Epoch 206/1000
27/27 [==============================] - ETA: 0s - loss: 0.0044
Epoch 206: loss improved from 0.00475 to 0.00442, saving model to /content/drive/MyDrive/Проекты/ML/Pets/rnn_mario_level_builder/data/weights-improvement-206-0.0044.hdf5
27/27 [==============================] - 1s 23ms/step - loss: 0.0044
Epoch 207/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0058
Epoch 207: loss did not improve from 0.00442
27/27 [==============================] - 1s 21ms/step - loss: 0.0058
Epoch 208/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0052
Epoch 208: loss did not improve from 0.00442
27/27 [==============================] - 1s 21ms/step - loss: 0.0049
Epoch 209/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0058
Epoch 209: loss did not improve from 0.00442
27/27 [==============================] - 1s 22ms/step - loss: 0.0055
Epoch 210/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0051
Epoch 210: loss did not improve from 0.00442
27/27 [==============================] - 1s 21ms/step - loss: 0.0049
Epoch 211/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0070
Epoch 211: loss did not improve from 0.00442
27/27 [==============================] - 1s 21ms/step - loss: 0.0071
Epoch 212/1000
27/27 [==============================] - ETA: 0s - loss: 0.0096
Epoch 212: loss did not improve from 0.00442
27/27 [==============================] - 1s 22ms/step - loss: 0.0096
Epoch 213/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0166
Epoch 213: loss did not improve from 0.00442
27/27 [==============================] - 1s 22ms/step - loss: 0.0158
Epoch 214/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0215
Epoch 214: loss did not improve from 0.00442
27/27 [==============================] - 1s 22ms/step - loss: 0.0219
Epoch 215/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0160
Epoch 215: loss did not improve from 0.00442
27/27 [==============================] - 1s 21ms/step - loss: 0.0151
Epoch 216/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0114
Epoch 216: loss did not improve from 0.00442
27/27 [==============================] - 1s 21ms/step - loss: 0.0122
Epoch 217/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0227
Epoch 217: loss did not improve from 0.00442
27/27 [==============================] - 1s 21ms/step - loss: 0.0233
Epoch 218/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0207
Epoch 218: loss did not improve from 0.00442
27/27 [==============================] - 1s 22ms/step - loss: 0.0216
Epoch 219/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0174
Epoch 219: loss did not improve from 0.00442
27/27 [==============================] - 1s 21ms/step - loss: 0.0166
Epoch 220/1000
27/27 [==============================] - ETA: 0s - loss: 0.0162
Epoch 220: loss did not improve from 0.00442
27/27 [==============================] - 1s 22ms/step - loss: 0.0162
Epoch 221/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0121
Epoch 221: loss did not improve from 0.00442
27/27 [==============================] - 1s 22ms/step - loss: 0.0130
Epoch 222/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0082
Epoch 222: loss did not improve from 0.00442
27/27 [==============================] - 1s 22ms/step - loss: 0.0080
Epoch 223/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0072
Epoch 223: loss did not improve from 0.00442
27/27 [==============================] - 1s 22ms/step - loss: 0.0069
Epoch 224/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0052
Epoch 224: loss did not improve from 0.00442
27/27 [==============================] - 1s 22ms/step - loss: 0.0053
Epoch 225/1000
27/27 [==============================] - ETA: 0s - loss: 0.0045
Epoch 225: loss did not improve from 0.00442
27/27 [==============================] - 1s 22ms/step - loss: 0.0045
Epoch 226/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0056
Epoch 226: loss did not improve from 0.00442
27/27 [==============================] - 1s 22ms/step - loss: 0.0053
Epoch 227/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0051
Epoch 227: loss did not improve from 0.00442
27/27 [==============================] - 1s 22ms/step - loss: 0.0050
Epoch 228/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0056
Epoch 228: loss did not improve from 0.00442
27/27 [==============================] - 1s 21ms/step - loss: 0.0053
Epoch 229/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0044
Epoch 229: loss improved from 0.00442 to 0.00417, saving model to /content/drive/MyDrive/Проекты/ML/Pets/rnn_mario_level_builder/data/weights-improvement-229-0.0042.hdf5
27/27 [==============================] - 1s 23ms/step - loss: 0.0042
Epoch 230/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0046
Epoch 230: loss did not improve from 0.00417
27/27 [==============================] - 1s 22ms/step - loss: 0.0044
Epoch 231/1000
27/27 [==============================] - ETA: 0s - loss: 0.0041
Epoch 231: loss improved from 0.00417 to 0.00410, saving model to /content/drive/MyDrive/Проекты/ML/Pets/rnn_mario_level_builder/data/weights-improvement-231-0.0041.hdf5
27/27 [==============================] - 1s 23ms/step - loss: 0.0041
Epoch 232/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0054
Epoch 232: loss did not improve from 0.00410
27/27 [==============================] - 1s 22ms/step - loss: 0.0051
Epoch 233/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0047
Epoch 233: loss did not improve from 0.00410
27/27 [==============================] - 1s 21ms/step - loss: 0.0048
Epoch 234/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0049
Epoch 234: loss did not improve from 0.00410
27/27 [==============================] - 1s 22ms/step - loss: 0.0047
Epoch 235/1000
27/27 [==============================] - ETA: 0s - loss: 0.0052
Epoch 235: loss did not improve from 0.00410
27/27 [==============================] - 1s 22ms/step - loss: 0.0052
Epoch 236/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0047
Epoch 236: loss did not improve from 0.00410
27/27 [==============================] - 1s 22ms/step - loss: 0.0044
Epoch 237/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0044
Epoch 237: loss did not improve from 0.00410
27/27 [==============================] - 1s 22ms/step - loss: 0.0042
Epoch 238/1000
27/27 [==============================] - ETA: 0s - loss: 0.0054
Epoch 238: loss did not improve from 0.00410
27/27 [==============================] - 1s 22ms/step - loss: 0.0054
Epoch 239/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0039
Epoch 239: loss did not improve from 0.00410
27/27 [==============================] - 1s 21ms/step - loss: 0.0041
Epoch 240/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0042
Epoch 240: loss improved from 0.00410 to 0.00402, saving model to /content/drive/MyDrive/Проекты/ML/Pets/rnn_mario_level_builder/data/weights-improvement-240-0.0040.hdf5
27/27 [==============================] - 1s 23ms/step - loss: 0.0040
Epoch 241/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0043
Epoch 241: loss did not improve from 0.00402
27/27 [==============================] - 1s 21ms/step - loss: 0.0041
Epoch 242/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0046
Epoch 242: loss did not improve from 0.00402
27/27 [==============================] - 1s 22ms/step - loss: 0.0044
Epoch 243/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0037
Epoch 243: loss did not improve from 0.00402
27/27 [==============================] - 1s 21ms/step - loss: 0.0046
Epoch 244/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0043
Epoch 244: loss did not improve from 0.00402
27/27 [==============================] - 1s 21ms/step - loss: 0.0041
Epoch 245/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0050
Epoch 245: loss did not improve from 0.00402
27/27 [==============================] - 1s 21ms/step - loss: 0.0047
Epoch 246/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0042
Epoch 246: loss improved from 0.00402 to 0.00394, saving model to /content/drive/MyDrive/Проекты/ML/Pets/rnn_mario_level_builder/data/weights-improvement-246-0.0039.hdf5
27/27 [==============================] - 1s 23ms/step - loss: 0.0039
Epoch 247/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0047
Epoch 247: loss did not improve from 0.00394
27/27 [==============================] - 1s 21ms/step - loss: 0.0044
Epoch 248/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0114
Epoch 248: loss did not improve from 0.00394
27/27 [==============================] - 1s 21ms/step - loss: 0.0117
Epoch 249/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0309
Epoch 249: loss did not improve from 0.00394
27/27 [==============================] - 1s 22ms/step - loss: 0.0331
Epoch 250/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0324
Epoch 250: loss did not improve from 0.00394
27/27 [==============================] - 1s 21ms/step - loss: 0.0333
Epoch 251/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0501
Epoch 251: loss did not improve from 0.00394
27/27 [==============================] - 1s 22ms/step - loss: 0.0585
Epoch 252/1000
27/27 [==============================] - ETA: 0s - loss: 0.0696
Epoch 252: loss did not improve from 0.00394
27/27 [==============================] - 1s 22ms/step - loss: 0.0696
Epoch 253/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0301
Epoch 253: loss did not improve from 0.00394
27/27 [==============================] - 1s 21ms/step - loss: 0.0292
Epoch 254/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0232
Epoch 254: loss did not improve from 0.00394
27/27 [==============================] - 1s 22ms/step - loss: 0.0258
Epoch 255/1000
26/27 [===========================&gt;..] - ETA: 0s - loss: 0.0200
Epoch 255: loss did not improve from 0.00394
27/27 [==============================] - 1s 23ms/step - loss: 0.0195
Epoch 256/1000
27/27 [==============================] - ETA: 0s - loss: 0.0156
Epoch 256: loss did not improve from 0.00394
27/27 [==============================] - 1s 22ms/step - loss: 0.0156
Epoch 257/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0087
Epoch 257: loss did not improve from 0.00394
27/27 [==============================] - 1s 22ms/step - loss: 0.0094
Epoch 258/1000
27/27 [==============================] - ETA: 0s - loss: 0.0079
Epoch 258: loss did not improve from 0.00394
27/27 [==============================] - 1s 22ms/step - loss: 0.0079
Epoch 259/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0081
Epoch 259: loss did not improve from 0.00394
27/27 [==============================] - 1s 22ms/step - loss: 0.0079
Epoch 260/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0087
Epoch 260: loss did not improve from 0.00394
27/27 [==============================] - 1s 21ms/step - loss: 0.0088
Epoch 261/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0084
Epoch 261: loss did not improve from 0.00394
27/27 [==============================] - 1s 22ms/step - loss: 0.0080
Epoch 262/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0109
Epoch 262: loss did not improve from 0.00394
27/27 [==============================] - 1s 22ms/step - loss: 0.0112
Epoch 263/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0106
Epoch 263: loss did not improve from 0.00394
27/27 [==============================] - 1s 22ms/step - loss: 0.0102
Epoch 264/1000
27/27 [==============================] - ETA: 0s - loss: 0.0111
Epoch 264: loss did not improve from 0.00394
27/27 [==============================] - 1s 22ms/step - loss: 0.0111
Epoch 265/1000
26/27 [===========================&gt;..] - ETA: 0s - loss: 0.0132
Epoch 265: loss did not improve from 0.00394
27/27 [==============================] - 1s 22ms/step - loss: 0.0134
Epoch 266/1000
27/27 [==============================] - ETA: 0s - loss: 0.0168
Epoch 266: loss did not improve from 0.00394
27/27 [==============================] - 1s 22ms/step - loss: 0.0168
Epoch 267/1000
27/27 [==============================] - ETA: 0s - loss: 0.0158
Epoch 267: loss did not improve from 0.00394
27/27 [==============================] - 1s 23ms/step - loss: 0.0158
Epoch 268/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0081
Epoch 268: loss did not improve from 0.00394
27/27 [==============================] - 1s 22ms/step - loss: 0.0079
Epoch 269/1000
27/27 [==============================] - ETA: 0s - loss: 0.0067
Epoch 269: loss did not improve from 0.00394
27/27 [==============================] - 1s 22ms/step - loss: 0.0067
Epoch 270/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0055
Epoch 270: loss did not improve from 0.00394
27/27 [==============================] - 1s 22ms/step - loss: 0.0055
Epoch 271/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0055
Epoch 271: loss did not improve from 0.00394
27/27 [==============================] - 1s 22ms/step - loss: 0.0053
Epoch 272/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0045
Epoch 272: loss did not improve from 0.00394
27/27 [==============================] - 1s 21ms/step - loss: 0.0043
Epoch 273/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0050
Epoch 273: loss did not improve from 0.00394
27/27 [==============================] - 1s 21ms/step - loss: 0.0048
Epoch 274/1000
27/27 [==============================] - ETA: 0s - loss: 0.0051
Epoch 274: loss did not improve from 0.00394
27/27 [==============================] - 1s 22ms/step - loss: 0.0051
Epoch 275/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0050
Epoch 275: loss did not improve from 0.00394
27/27 [==============================] - 1s 21ms/step - loss: 0.0047
Epoch 276/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0053
Epoch 276: loss did not improve from 0.00394
27/27 [==============================] - 1s 22ms/step - loss: 0.0051
Epoch 277/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0045
Epoch 277: loss did not improve from 0.00394
27/27 [==============================] - 1s 21ms/step - loss: 0.0043
Epoch 278/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0051
Epoch 278: loss did not improve from 0.00394
27/27 [==============================] - 1s 22ms/step - loss: 0.0048
Epoch 279/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0048
Epoch 279: loss did not improve from 0.00394
27/27 [==============================] - 1s 21ms/step - loss: 0.0046
Epoch 280/1000
27/27 [==============================] - ETA: 0s - loss: 0.0048
Epoch 280: loss did not improve from 0.00394
27/27 [==============================] - 1s 22ms/step - loss: 0.0048
Epoch 281/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0059
Epoch 281: loss did not improve from 0.00394
27/27 [==============================] - 1s 21ms/step - loss: 0.0056
Epoch 282/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0041
Epoch 282: loss improved from 0.00394 to 0.00385, saving model to /content/drive/MyDrive/Проекты/ML/Pets/rnn_mario_level_builder/data/weights-improvement-282-0.0039.hdf5
27/27 [==============================] - 1s 23ms/step - loss: 0.0039
Epoch 283/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0035
Epoch 283: loss did not improve from 0.00385
27/27 [==============================] - 1s 21ms/step - loss: 0.0042
Epoch 284/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0046
Epoch 284: loss did not improve from 0.00385
27/27 [==============================] - 1s 21ms/step - loss: 0.0044
Epoch 285/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0055
Epoch 285: loss did not improve from 0.00385
27/27 [==============================] - 1s 22ms/step - loss: 0.0052
Epoch 286/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0064
Epoch 286: loss did not improve from 0.00385
27/27 [==============================] - 1s 21ms/step - loss: 0.0060
Epoch 287/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0041
Epoch 287: loss did not improve from 0.00385
27/27 [==============================] - 1s 22ms/step - loss: 0.0039
Epoch 288/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0051
Epoch 288: loss did not improve from 0.00385
27/27 [==============================] - 1s 22ms/step - loss: 0.0048
Epoch 289/1000
27/27 [==============================] - ETA: 0s - loss: 0.0051
Epoch 289: loss did not improve from 0.00385
27/27 [==============================] - 1s 22ms/step - loss: 0.0051
Epoch 290/1000
26/27 [===========================&gt;..] - ETA: 0s - loss: 0.0067
Epoch 290: loss did not improve from 0.00385
27/27 [==============================] - 1s 23ms/step - loss: 0.0065
Epoch 291/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0051
Epoch 291: loss did not improve from 0.00385
27/27 [==============================] - 1s 22ms/step - loss: 0.0049
Epoch 292/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0048
Epoch 292: loss did not improve from 0.00385
27/27 [==============================] - 1s 22ms/step - loss: 0.0047
Epoch 293/1000
27/27 [==============================] - ETA: 0s - loss: 0.0072
Epoch 293: loss did not improve from 0.00385
27/27 [==============================] - 1s 22ms/step - loss: 0.0072
Epoch 294/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0084
Epoch 294: loss did not improve from 0.00385
27/27 [==============================] - 1s 22ms/step - loss: 0.0083
Epoch 295/1000
27/27 [==============================] - ETA: 0s - loss: 0.0112
Epoch 295: loss did not improve from 0.00385
27/27 [==============================] - 1s 22ms/step - loss: 0.0112
Epoch 296/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0097
Epoch 296: loss did not improve from 0.00385
27/27 [==============================] - 1s 22ms/step - loss: 0.0104
Epoch 297/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0290
Epoch 297: loss did not improve from 0.00385
27/27 [==============================] - 1s 22ms/step - loss: 0.0301
Epoch 298/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0331
Epoch 298: loss did not improve from 0.00385
27/27 [==============================] - 1s 22ms/step - loss: 0.0321
Epoch 299/1000
27/27 [==============================] - ETA: 0s - loss: 0.0269
Epoch 299: loss did not improve from 0.00385
27/27 [==============================] - 1s 22ms/step - loss: 0.0269
Epoch 300/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0217
Epoch 300: loss did not improve from 0.00385
27/27 [==============================] - 1s 22ms/step - loss: 0.0220
Epoch 301/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0180
Epoch 301: loss did not improve from 0.00385
27/27 [==============================] - 1s 21ms/step - loss: 0.0173
Epoch 302/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0145
Epoch 302: loss did not improve from 0.00385
27/27 [==============================] - 1s 22ms/step - loss: 0.0151
Epoch 303/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0119
Epoch 303: loss did not improve from 0.00385
27/27 [==============================] - 1s 22ms/step - loss: 0.0118
Epoch 304/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0083
Epoch 304: loss did not improve from 0.00385
27/27 [==============================] - 1s 22ms/step - loss: 0.0079
Epoch 305/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0110
Epoch 305: loss did not improve from 0.00385
27/27 [==============================] - 1s 22ms/step - loss: 0.0108
Epoch 306/1000
27/27 [==============================] - ETA: 0s - loss: 0.0201
Epoch 306: loss did not improve from 0.00385
27/27 [==============================] - 1s 22ms/step - loss: 0.0201
Epoch 307/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0133
Epoch 307: loss did not improve from 0.00385
27/27 [==============================] - 1s 22ms/step - loss: 0.0143
Epoch 308/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0123
Epoch 308: loss did not improve from 0.00385
27/27 [==============================] - 1s 22ms/step - loss: 0.0132
Epoch 309/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0126
Epoch 309: loss did not improve from 0.00385
27/27 [==============================] - 1s 22ms/step - loss: 0.0119
Epoch 310/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0084
Epoch 310: loss did not improve from 0.00385
27/27 [==============================] - 1s 22ms/step - loss: 0.0097
Epoch 311/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0184
Epoch 311: loss did not improve from 0.00385
27/27 [==============================] - 1s 22ms/step - loss: 0.0177
Epoch 312/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0084
Epoch 312: loss did not improve from 0.00385
27/27 [==============================] - 1s 22ms/step - loss: 0.0096
Epoch 313/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0107
Epoch 313: loss did not improve from 0.00385
27/27 [==============================] - 1s 22ms/step - loss: 0.0109
Epoch 314/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0074
Epoch 314: loss did not improve from 0.00385
27/27 [==============================] - 1s 22ms/step - loss: 0.0072
Epoch 315/1000
27/27 [==============================] - ETA: 0s - loss: 0.0061
Epoch 315: loss did not improve from 0.00385
27/27 [==============================] - 1s 23ms/step - loss: 0.0061
Epoch 316/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0050
Epoch 316: loss did not improve from 0.00385
27/27 [==============================] - 1s 22ms/step - loss: 0.0050
Epoch 317/1000
27/27 [==============================] - ETA: 0s - loss: 0.0043
Epoch 317: loss did not improve from 0.00385
27/27 [==============================] - 1s 22ms/step - loss: 0.0043
Epoch 318/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0044
Epoch 318: loss did not improve from 0.00385
27/27 [==============================] - 1s 22ms/step - loss: 0.0042
Epoch 319/1000
27/27 [==============================] - ETA: 0s - loss: 0.0039
Epoch 319: loss did not improve from 0.00385
27/27 [==============================] - 1s 22ms/step - loss: 0.0039
Epoch 320/1000
26/27 [===========================&gt;..] - ETA: 0s - loss: 0.0036
Epoch 320: loss improved from 0.00385 to 0.00355, saving model to /content/drive/MyDrive/Проекты/ML/Pets/rnn_mario_level_builder/data/weights-improvement-320-0.0036.hdf5
27/27 [==============================] - 1s 24ms/step - loss: 0.0036
Epoch 321/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0043
Epoch 321: loss did not improve from 0.00355
27/27 [==============================] - 1s 21ms/step - loss: 0.0041
Epoch 322/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0041
Epoch 322: loss did not improve from 0.00355
27/27 [==============================] - 1s 22ms/step - loss: 0.0041
Epoch 323/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0041
Epoch 323: loss did not improve from 0.00355
27/27 [==============================] - 1s 22ms/step - loss: 0.0039
Epoch 324/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0030
Epoch 324: loss did not improve from 0.00355
27/27 [==============================] - 1s 22ms/step - loss: 0.0044
Epoch 325/1000
26/27 [===========================&gt;..] - ETA: 0s - loss: 0.0044
Epoch 325: loss did not improve from 0.00355
27/27 [==============================] - 1s 23ms/step - loss: 0.0043
Epoch 326/1000
27/27 [==============================] - ETA: 0s - loss: 0.0047
Epoch 326: loss did not improve from 0.00355
27/27 [==============================] - 1s 22ms/step - loss: 0.0047
Epoch 327/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0049
Epoch 327: loss did not improve from 0.00355
27/27 [==============================] - 1s 21ms/step - loss: 0.0046
Epoch 328/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0030
Epoch 328: loss did not improve from 0.00355
27/27 [==============================] - 1s 21ms/step - loss: 0.0038
Epoch 329/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0041
Epoch 329: loss did not improve from 0.00355
27/27 [==============================] - 1s 22ms/step - loss: 0.0039
Epoch 330/1000
27/27 [==============================] - ETA: 0s - loss: 0.0044
Epoch 330: loss did not improve from 0.00355
27/27 [==============================] - 1s 22ms/step - loss: 0.0044
Epoch 331/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0042
Epoch 331: loss did not improve from 0.00355
27/27 [==============================] - 1s 22ms/step - loss: 0.0039
Epoch 332/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0040
Epoch 332: loss did not improve from 0.00355
27/27 [==============================] - 1s 22ms/step - loss: 0.0054
Epoch 333/1000
27/27 [==============================] - ETA: 0s - loss: 0.0090
Epoch 333: loss did not improve from 0.00355
27/27 [==============================] - 1s 22ms/step - loss: 0.0090
Epoch 334/1000
27/27 [==============================] - ETA: 0s - loss: 0.0301
Epoch 334: loss did not improve from 0.00355
27/27 [==============================] - 1s 22ms/step - loss: 0.0301
Epoch 335/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0329
Epoch 335: loss did not improve from 0.00355
27/27 [==============================] - 1s 22ms/step - loss: 0.0330
Epoch 336/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0341
Epoch 336: loss did not improve from 0.00355
27/27 [==============================] - 1s 22ms/step - loss: 0.0322
Epoch 337/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0272
Epoch 337: loss did not improve from 0.00355
27/27 [==============================] - 1s 22ms/step - loss: 0.0271
Epoch 338/1000
27/27 [==============================] - ETA: 0s - loss: 0.0135
Epoch 338: loss did not improve from 0.00355
27/27 [==============================] - 1s 22ms/step - loss: 0.0135
Epoch 339/1000
27/27 [==============================] - ETA: 0s - loss: 0.0117
Epoch 339: loss did not improve from 0.00355
27/27 [==============================] - 1s 22ms/step - loss: 0.0117
Epoch 340/1000
27/27 [==============================] - ETA: 0s - loss: 0.0085
Epoch 340: loss did not improve from 0.00355
27/27 [==============================] - 1s 22ms/step - loss: 0.0085
Epoch 341/1000
27/27 [==============================] - ETA: 0s - loss: 0.0078
Epoch 341: loss did not improve from 0.00355
27/27 [==============================] - 1s 22ms/step - loss: 0.0078
Epoch 342/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0069
Epoch 342: loss did not improve from 0.00355
27/27 [==============================] - 1s 22ms/step - loss: 0.0065
Epoch 343/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0075
Epoch 343: loss did not improve from 0.00355
27/27 [==============================] - 1s 22ms/step - loss: 0.0071
Epoch 344/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0066
Epoch 344: loss did not improve from 0.00355
27/27 [==============================] - 1s 22ms/step - loss: 0.0080
Epoch 345/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0102
Epoch 345: loss did not improve from 0.00355
27/27 [==============================] - 1s 21ms/step - loss: 0.0096
Epoch 346/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0044
Epoch 346: loss did not improve from 0.00355
27/27 [==============================] - 1s 22ms/step - loss: 0.0059
Epoch 347/1000
27/27 [==============================] - ETA: 0s - loss: 0.0039
Epoch 347: loss did not improve from 0.00355
27/27 [==============================] - 1s 22ms/step - loss: 0.0039
Epoch 348/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0042
Epoch 348: loss did not improve from 0.00355
27/27 [==============================] - 1s 21ms/step - loss: 0.0041
Epoch 349/1000
27/27 [==============================] - ETA: 0s - loss: 0.0041
Epoch 349: loss did not improve from 0.00355
27/27 [==============================] - 1s 23ms/step - loss: 0.0041
Epoch 350/1000
27/27 [==============================] - ETA: 0s - loss: 0.0050
Epoch 350: loss did not improve from 0.00355
27/27 [==============================] - 1s 22ms/step - loss: 0.0050
Epoch 351/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0039
Epoch 351: loss did not improve from 0.00355
27/27 [==============================] - 1s 22ms/step - loss: 0.0038
Epoch 352/1000
27/27 [==============================] - ETA: 0s - loss: 0.0037
Epoch 352: loss did not improve from 0.00355
27/27 [==============================] - 1s 22ms/step - loss: 0.0037
Epoch 353/1000
27/27 [==============================] - ETA: 0s - loss: 0.0042
Epoch 353: loss did not improve from 0.00355
27/27 [==============================] - 1s 22ms/step - loss: 0.0042
Epoch 354/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0044
Epoch 354: loss did not improve from 0.00355
27/27 [==============================] - 1s 22ms/step - loss: 0.0041
Epoch 355/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0040
Epoch 355: loss did not improve from 0.00355
27/27 [==============================] - 1s 22ms/step - loss: 0.0038
Epoch 356/1000
26/27 [===========================&gt;..] - ETA: 0s - loss: 0.0037
Epoch 356: loss did not improve from 0.00355
27/27 [==============================] - 1s 22ms/step - loss: 0.0036
Epoch 357/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0038
Epoch 357: loss did not improve from 0.00355
27/27 [==============================] - 1s 21ms/step - loss: 0.0036
Epoch 358/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0038
Epoch 358: loss did not improve from 0.00355
27/27 [==============================] - 1s 22ms/step - loss: 0.0037
Epoch 359/1000
27/27 [==============================] - ETA: 0s - loss: 0.0040
Epoch 359: loss did not improve from 0.00355
27/27 [==============================] - 1s 22ms/step - loss: 0.0040
Epoch 360/1000
26/27 [===========================&gt;..] - ETA: 0s - loss: 0.0036
Epoch 360: loss improved from 0.00355 to 0.00348, saving model to /content/drive/MyDrive/Проекты/ML/Pets/rnn_mario_level_builder/data/weights-improvement-360-0.0035.hdf5
27/27 [==============================] - 1s 24ms/step - loss: 0.0035
Epoch 361/1000
27/27 [==============================] - ETA: 0s - loss: 0.0036
Epoch 361: loss did not improve from 0.00348
27/27 [==============================] - 1s 22ms/step - loss: 0.0036
Epoch 362/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0035
Epoch 362: loss improved from 0.00348 to 0.00334, saving model to /content/drive/MyDrive/Проекты/ML/Pets/rnn_mario_level_builder/data/weights-improvement-362-0.0033.hdf5
27/27 [==============================] - 1s 23ms/step - loss: 0.0033
Epoch 363/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0045
Epoch 363: loss did not improve from 0.00334
27/27 [==============================] - 1s 22ms/step - loss: 0.0042
Epoch 364/1000
26/27 [===========================&gt;..] - ETA: 0s - loss: 0.0043
Epoch 364: loss did not improve from 0.00334
27/27 [==============================] - 1s 22ms/step - loss: 0.0042
Epoch 365/1000
27/27 [==============================] - ETA: 0s - loss: 0.0040
Epoch 365: loss did not improve from 0.00334
27/27 [==============================] - 1s 22ms/step - loss: 0.0040
Epoch 366/1000
27/27 [==============================] - ETA: 0s - loss: 0.0037
Epoch 366: loss did not improve from 0.00334
27/27 [==============================] - 1s 22ms/step - loss: 0.0037
Epoch 367/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0033
Epoch 367: loss improved from 0.00334 to 0.00313, saving model to /content/drive/MyDrive/Проекты/ML/Pets/rnn_mario_level_builder/data/weights-improvement-367-0.0031.hdf5
27/27 [==============================] - 1s 24ms/step - loss: 0.0031
Epoch 368/1000
27/27 [==============================] - ETA: 0s - loss: 0.0033
Epoch 368: loss did not improve from 0.00313
27/27 [==============================] - 1s 22ms/step - loss: 0.0033
Epoch 369/1000
27/27 [==============================] - ETA: 0s - loss: 0.0037
Epoch 369: loss did not improve from 0.00313
27/27 [==============================] - 1s 22ms/step - loss: 0.0037
Epoch 370/1000
27/27 [==============================] - ETA: 0s - loss: 0.0036
Epoch 370: loss did not improve from 0.00313
27/27 [==============================] - 1s 22ms/step - loss: 0.0036
Epoch 371/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0030
Epoch 371: loss improved from 0.00313 to 0.00285, saving model to /content/drive/MyDrive/Проекты/ML/Pets/rnn_mario_level_builder/data/weights-improvement-371-0.0029.hdf5
27/27 [==============================] - 1s 24ms/step - loss: 0.0029
Epoch 372/1000
27/27 [==============================] - ETA: 0s - loss: 0.0032
Epoch 372: loss did not improve from 0.00285
27/27 [==============================] - 1s 22ms/step - loss: 0.0032
Epoch 373/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0038
Epoch 373: loss did not improve from 0.00285
27/27 [==============================] - 1s 22ms/step - loss: 0.0036
Epoch 374/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0037
Epoch 374: loss did not improve from 0.00285
27/27 [==============================] - 1s 22ms/step - loss: 0.0036
Epoch 375/1000
27/27 [==============================] - ETA: 0s - loss: 0.0039
Epoch 375: loss did not improve from 0.00285
27/27 [==============================] - 1s 22ms/step - loss: 0.0039
Epoch 376/1000
26/27 [===========================&gt;..] - ETA: 0s - loss: 0.0030
Epoch 376: loss did not improve from 0.00285
27/27 [==============================] - 1s 23ms/step - loss: 0.0029
Epoch 377/1000
26/27 [===========================&gt;..] - ETA: 0s - loss: 0.0034
Epoch 377: loss did not improve from 0.00285
27/27 [==============================] - 1s 23ms/step - loss: 0.0033
Epoch 378/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0033
Epoch 378: loss did not improve from 0.00285
27/27 [==============================] - 1s 22ms/step - loss: 0.0031
Epoch 379/1000
27/27 [==============================] - ETA: 0s - loss: 0.0152
Epoch 379: loss did not improve from 0.00285
27/27 [==============================] - 1s 22ms/step - loss: 0.0152
Epoch 380/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0475
Epoch 380: loss did not improve from 0.00285
27/27 [==============================] - 1s 22ms/step - loss: 0.0465
Epoch 381/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0303
Epoch 381: loss did not improve from 0.00285
27/27 [==============================] - 1s 22ms/step - loss: 0.0292
Epoch 382/1000
27/27 [==============================] - ETA: 0s - loss: 0.0280
Epoch 382: loss did not improve from 0.00285
27/27 [==============================] - 1s 23ms/step - loss: 0.0280
Epoch 383/1000
26/27 [===========================&gt;..] - ETA: 0s - loss: 0.0256
Epoch 383: loss did not improve from 0.00285
27/27 [==============================] - 1s 23ms/step - loss: 0.0277
Epoch 384/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0220
Epoch 384: loss did not improve from 0.00285
27/27 [==============================] - 1s 22ms/step - loss: 0.0226
Epoch 385/1000
27/27 [==============================] - ETA: 0s - loss: 0.0188
Epoch 385: loss did not improve from 0.00285
27/27 [==============================] - 1s 23ms/step - loss: 0.0188
Epoch 386/1000
27/27 [==============================] - ETA: 0s - loss: 0.0373
Epoch 386: loss did not improve from 0.00285
27/27 [==============================] - 1s 22ms/step - loss: 0.0373
Epoch 387/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0353
Epoch 387: loss did not improve from 0.00285
27/27 [==============================] - 1s 22ms/step - loss: 0.0345
Epoch 388/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0262
Epoch 388: loss did not improve from 0.00285
27/27 [==============================] - 1s 22ms/step - loss: 0.0257
Epoch 389/1000
27/27 [==============================] - ETA: 0s - loss: 0.0209
Epoch 389: loss did not improve from 0.00285
27/27 [==============================] - 1s 22ms/step - loss: 0.0209
Epoch 390/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0157
Epoch 390: loss did not improve from 0.00285
27/27 [==============================] - 1s 22ms/step - loss: 0.0153
Epoch 391/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0092
Epoch 391: loss did not improve from 0.00285
27/27 [==============================] - 1s 22ms/step - loss: 0.0087
Epoch 392/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0102
Epoch 392: loss did not improve from 0.00285
27/27 [==============================] - 1s 22ms/step - loss: 0.0108
Epoch 393/1000
26/27 [===========================&gt;..] - ETA: 0s - loss: 0.0173
Epoch 393: loss did not improve from 0.00285
27/27 [==============================] - 1s 22ms/step - loss: 0.0182
Epoch 394/1000
27/27 [==============================] - ETA: 0s - loss: 0.0099
Epoch 394: loss did not improve from 0.00285
27/27 [==============================] - 1s 22ms/step - loss: 0.0099
Epoch 395/1000
27/27 [==============================] - ETA: 0s - loss: 0.0102
Epoch 395: loss did not improve from 0.00285
27/27 [==============================] - 1s 22ms/step - loss: 0.0102
Epoch 396/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0107
Epoch 396: loss did not improve from 0.00285
27/27 [==============================] - 1s 22ms/step - loss: 0.0105
Epoch 397/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0086
Epoch 397: loss did not improve from 0.00285
27/27 [==============================] - 1s 22ms/step - loss: 0.0083
Epoch 398/1000
26/27 [===========================&gt;..] - ETA: 0s - loss: 0.0068
Epoch 398: loss did not improve from 0.00285
27/27 [==============================] - 1s 23ms/step - loss: 0.0066
Epoch 399/1000
26/27 [===========================&gt;..] - ETA: 0s - loss: 0.0077
Epoch 399: loss did not improve from 0.00285
27/27 [==============================] - 1s 22ms/step - loss: 0.0077
Epoch 400/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0040
Epoch 400: loss did not improve from 0.00285
27/27 [==============================] - 1s 22ms/step - loss: 0.0049
Epoch 401/1000
26/27 [===========================&gt;..] - ETA: 0s - loss: 0.0051
Epoch 401: loss did not improve from 0.00285
27/27 [==============================] - 1s 23ms/step - loss: 0.0050
Epoch 402/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0118
Epoch 402: loss did not improve from 0.00285
27/27 [==============================] - 1s 22ms/step - loss: 0.0118
Epoch 403/1000
27/27 [==============================] - ETA: 0s - loss: 0.0094
Epoch 403: loss did not improve from 0.00285
27/27 [==============================] - 1s 22ms/step - loss: 0.0094
Epoch 404/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0076
Epoch 404: loss did not improve from 0.00285
27/27 [==============================] - 1s 22ms/step - loss: 0.0073
Epoch 405/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0053
Epoch 405: loss did not improve from 0.00285
27/27 [==============================] - 1s 22ms/step - loss: 0.0050
Epoch 406/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0042
Epoch 406: loss did not improve from 0.00285
27/27 [==============================] - 1s 22ms/step - loss: 0.0043
Epoch 407/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0047
Epoch 407: loss did not improve from 0.00285
27/27 [==============================] - 1s 21ms/step - loss: 0.0045
Epoch 408/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0057
Epoch 408: loss did not improve from 0.00285
27/27 [==============================] - 1s 22ms/step - loss: 0.0058
Epoch 409/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0034
Epoch 409: loss did not improve from 0.00285
27/27 [==============================] - 1s 22ms/step - loss: 0.0049
Epoch 410/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0038
Epoch 410: loss did not improve from 0.00285
27/27 [==============================] - 1s 22ms/step - loss: 0.0037
Epoch 411/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0050
Epoch 411: loss did not improve from 0.00285
27/27 [==============================] - 1s 22ms/step - loss: 0.0047
Epoch 412/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0053
Epoch 412: loss did not improve from 0.00285
27/27 [==============================] - 1s 22ms/step - loss: 0.0064
Epoch 413/1000
26/27 [===========================&gt;..] - ETA: 0s - loss: 0.0119
Epoch 413: loss did not improve from 0.00285
27/27 [==============================] - 1s 22ms/step - loss: 0.0116
Epoch 414/1000
27/27 [==============================] - ETA: 0s - loss: 0.0209
Epoch 414: loss did not improve from 0.00285
27/27 [==============================] - 1s 23ms/step - loss: 0.0209
Epoch 415/1000
26/27 [===========================&gt;..] - ETA: 0s - loss: 0.0203
Epoch 415: loss did not improve from 0.00285
27/27 [==============================] - 1s 22ms/step - loss: 0.0199
Epoch 416/1000
26/27 [===========================&gt;..] - ETA: 0s - loss: 0.0115
Epoch 416: loss did not improve from 0.00285
27/27 [==============================] - 1s 23ms/step - loss: 0.0112
Epoch 417/1000
27/27 [==============================] - ETA: 0s - loss: 0.0148
Epoch 417: loss did not improve from 0.00285
27/27 [==============================] - 1s 23ms/step - loss: 0.0148
Epoch 418/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0172
Epoch 418: loss did not improve from 0.00285
27/27 [==============================] - 1s 22ms/step - loss: 0.0181
Epoch 419/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0101
Epoch 419: loss did not improve from 0.00285
27/27 [==============================] - 1s 22ms/step - loss: 0.0118
Epoch 420/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0147
Epoch 420: loss did not improve from 0.00285
27/27 [==============================] - 1s 22ms/step - loss: 0.0140
Epoch 421/1000
26/27 [===========================&gt;..] - ETA: 0s - loss: 0.0144
Epoch 421: loss did not improve from 0.00285
27/27 [==============================] - 1s 23ms/step - loss: 0.0145
Epoch 422/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0221
Epoch 422: loss did not improve from 0.00285
27/27 [==============================] - 1s 22ms/step - loss: 0.0212
Epoch 423/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0167
Epoch 423: loss did not improve from 0.00285
27/27 [==============================] - 1s 22ms/step - loss: 0.0159
Epoch 424/1000
26/27 [===========================&gt;..] - ETA: 0s - loss: 0.0098
Epoch 424: loss did not improve from 0.00285
27/27 [==============================] - 1s 22ms/step - loss: 0.0096
Epoch 425/1000
27/27 [==============================] - ETA: 0s - loss: 0.0109
Epoch 425: loss did not improve from 0.00285
27/27 [==============================] - 1s 22ms/step - loss: 0.0109
Epoch 426/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0063
Epoch 426: loss did not improve from 0.00285
27/27 [==============================] - 1s 22ms/step - loss: 0.0068
Epoch 427/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0056
Epoch 427: loss did not improve from 0.00285
27/27 [==============================] - 1s 22ms/step - loss: 0.0054
Epoch 428/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0052
Epoch 428: loss did not improve from 0.00285
27/27 [==============================] - 1s 22ms/step - loss: 0.0049
Epoch 429/1000
27/27 [==============================] - ETA: 0s - loss: 0.0043
Epoch 429: loss did not improve from 0.00285
27/27 [==============================] - 1s 22ms/step - loss: 0.0043
Epoch 430/1000
27/27 [==============================] - ETA: 0s - loss: 0.0045
Epoch 430: loss did not improve from 0.00285
27/27 [==============================] - 1s 23ms/step - loss: 0.0045
Epoch 431/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0039
Epoch 431: loss did not improve from 0.00285
27/27 [==============================] - 1s 22ms/step - loss: 0.0037
Epoch 432/1000
26/27 [===========================&gt;..] - ETA: 0s - loss: 0.0036
Epoch 432: loss did not improve from 0.00285
27/27 [==============================] - 1s 22ms/step - loss: 0.0036
Epoch 433/1000
27/27 [==============================] - ETA: 0s - loss: 0.0036
Epoch 433: loss did not improve from 0.00285
27/27 [==============================] - 1s 22ms/step - loss: 0.0036
Epoch 434/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0036
Epoch 434: loss did not improve from 0.00285
27/27 [==============================] - 1s 21ms/step - loss: 0.0037
Epoch 435/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0039
Epoch 435: loss did not improve from 0.00285
27/27 [==============================] - 1s 22ms/step - loss: 0.0038
Epoch 436/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0039
Epoch 436: loss did not improve from 0.00285
27/27 [==============================] - 1s 21ms/step - loss: 0.0037
Epoch 437/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0040
Epoch 437: loss did not improve from 0.00285
27/27 [==============================] - 1s 22ms/step - loss: 0.0038
Epoch 438/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0039
Epoch 438: loss did not improve from 0.00285
27/27 [==============================] - 1s 22ms/step - loss: 0.0037
Epoch 439/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0040
Epoch 439: loss did not improve from 0.00285
27/27 [==============================] - 1s 21ms/step - loss: 0.0037
Epoch 440/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0037
Epoch 440: loss did not improve from 0.00285
27/27 [==============================] - 1s 22ms/step - loss: 0.0035
Epoch 441/1000
26/27 [===========================&gt;..] - ETA: 0s - loss: 0.0039
Epoch 441: loss did not improve from 0.00285
27/27 [==============================] - 1s 22ms/step - loss: 0.0039
Epoch 442/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0031
Epoch 442: loss did not improve from 0.00285
27/27 [==============================] - 1s 22ms/step - loss: 0.0030
Epoch 443/1000
27/27 [==============================] - ETA: 0s - loss: 0.0034
Epoch 443: loss did not improve from 0.00285
27/27 [==============================] - 1s 22ms/step - loss: 0.0034
Epoch 444/1000
26/27 [===========================&gt;..] - ETA: 0s - loss: 0.0033
Epoch 444: loss did not improve from 0.00285
27/27 [==============================] - 1s 23ms/step - loss: 0.0033
Epoch 445/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0031
Epoch 445: loss did not improve from 0.00285
27/27 [==============================] - 1s 22ms/step - loss: 0.0030
Epoch 446/1000
27/27 [==============================] - ETA: 0s - loss: 0.0035
Epoch 446: loss did not improve from 0.00285
27/27 [==============================] - 1s 22ms/step - loss: 0.0035
Epoch 447/1000
26/27 [===========================&gt;..] - ETA: 0s - loss: 0.0035
Epoch 447: loss did not improve from 0.00285
27/27 [==============================] - 1s 23ms/step - loss: 0.0034
Epoch 448/1000
27/27 [==============================] - ETA: 0s - loss: 0.0033
Epoch 448: loss did not improve from 0.00285
27/27 [==============================] - 1s 22ms/step - loss: 0.0033
Epoch 449/1000
27/27 [==============================] - ETA: 0s - loss: 0.0037
Epoch 449: loss did not improve from 0.00285
27/27 [==============================] - 1s 23ms/step - loss: 0.0037
Epoch 450/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0035
Epoch 450: loss did not improve from 0.00285
27/27 [==============================] - 1s 22ms/step - loss: 0.0033
Epoch 451/1000
27/27 [==============================] - ETA: 0s - loss: 0.0034
Epoch 451: loss did not improve from 0.00285
27/27 [==============================] - 1s 23ms/step - loss: 0.0034
Epoch 452/1000
27/27 [==============================] - ETA: 0s - loss: 0.0033
Epoch 452: loss did not improve from 0.00285
27/27 [==============================] - 1s 22ms/step - loss: 0.0033
Epoch 453/1000
27/27 [==============================] - ETA: 0s - loss: 0.0033
Epoch 453: loss did not improve from 0.00285
27/27 [==============================] - 1s 22ms/step - loss: 0.0033
Epoch 454/1000
27/27 [==============================] - ETA: 0s - loss: 0.0045
Epoch 454: loss did not improve from 0.00285
27/27 [==============================] - 1s 22ms/step - loss: 0.0045
Epoch 455/1000
27/27 [==============================] - ETA: 0s - loss: 0.0038
Epoch 455: loss did not improve from 0.00285
27/27 [==============================] - 1s 22ms/step - loss: 0.0038
Epoch 456/1000
27/27 [==============================] - ETA: 0s - loss: 0.0024
Epoch 456: loss improved from 0.00285 to 0.00240, saving model to /content/drive/MyDrive/Проекты/ML/Pets/rnn_mario_level_builder/data/weights-improvement-456-0.0024.hdf5
27/27 [==============================] - 1s 24ms/step - loss: 0.0024
Epoch 457/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0037
Epoch 457: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0035
Epoch 458/1000
26/27 [===========================&gt;..] - ETA: 0s - loss: 0.0034
Epoch 458: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0033
Epoch 459/1000
26/27 [===========================&gt;..] - ETA: 0s - loss: 0.0036
Epoch 459: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0035
Epoch 460/1000
27/27 [==============================] - ETA: 0s - loss: 0.0029
Epoch 460: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0029
Epoch 461/1000
27/27 [==============================] - ETA: 0s - loss: 0.0031
Epoch 461: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0031
Epoch 462/1000
26/27 [===========================&gt;..] - ETA: 0s - loss: 0.0030
Epoch 462: loss did not improve from 0.00240
27/27 [==============================] - 1s 23ms/step - loss: 0.0030
Epoch 463/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0038
Epoch 463: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0036
Epoch 464/1000
27/27 [==============================] - ETA: 0s - loss: 0.0038
Epoch 464: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0038
Epoch 465/1000
27/27 [==============================] - ETA: 0s - loss: 0.0032
Epoch 465: loss did not improve from 0.00240
27/27 [==============================] - 1s 23ms/step - loss: 0.0032
Epoch 466/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0030
Epoch 466: loss did not improve from 0.00240
27/27 [==============================] - 1s 23ms/step - loss: 0.0036
Epoch 467/1000
26/27 [===========================&gt;..] - ETA: 0s - loss: 0.0031
Epoch 467: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0030
Epoch 468/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0025
Epoch 468: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0034
Epoch 469/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0033
Epoch 469: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0031
Epoch 470/1000
27/27 [==============================] - ETA: 0s - loss: 0.0032
Epoch 470: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0032
Epoch 471/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0036
Epoch 471: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0034
Epoch 472/1000
27/27 [==============================] - ETA: 0s - loss: 0.0033
Epoch 472: loss did not improve from 0.00240
27/27 [==============================] - 1s 23ms/step - loss: 0.0033
Epoch 473/1000
26/27 [===========================&gt;..] - ETA: 0s - loss: 0.0036
Epoch 473: loss did not improve from 0.00240
27/27 [==============================] - 1s 23ms/step - loss: 0.0035
Epoch 474/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0038
Epoch 474: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0036
Epoch 475/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0031
Epoch 475: loss did not improve from 0.00240
27/27 [==============================] - 1s 23ms/step - loss: 0.0030
Epoch 476/1000
27/27 [==============================] - ETA: 0s - loss: 0.0034
Epoch 476: loss did not improve from 0.00240
27/27 [==============================] - 1s 23ms/step - loss: 0.0034
Epoch 477/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0027
Epoch 477: loss did not improve from 0.00240
27/27 [==============================] - 1s 24ms/step - loss: 0.0029
Epoch 478/1000
27/27 [==============================] - ETA: 0s - loss: 0.0033
Epoch 478: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0033
Epoch 479/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0052
Epoch 479: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0050
Epoch 480/1000
26/27 [===========================&gt;..] - ETA: 0s - loss: 0.0246
Epoch 480: loss did not improve from 0.00240
27/27 [==============================] - 1s 23ms/step - loss: 0.0241
Epoch 481/1000
26/27 [===========================&gt;..] - ETA: 0s - loss: 0.0511
Epoch 481: loss did not improve from 0.00240
27/27 [==============================] - 1s 23ms/step - loss: 0.0503
Epoch 482/1000
27/27 [==============================] - ETA: 0s - loss: 0.0438
Epoch 482: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0438
Epoch 483/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0711
Epoch 483: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0721
Epoch 484/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0330
Epoch 484: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0317
Epoch 485/1000
27/27 [==============================] - ETA: 0s - loss: 0.0293
Epoch 485: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0293
Epoch 486/1000
26/27 [===========================&gt;..] - ETA: 0s - loss: 0.0158
Epoch 486: loss did not improve from 0.00240
27/27 [==============================] - 1s 23ms/step - loss: 0.0174
Epoch 487/1000
27/27 [==============================] - ETA: 0s - loss: 0.0253
Epoch 487: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0253
Epoch 488/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0226
Epoch 488: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0234
Epoch 489/1000
27/27 [==============================] - ETA: 0s - loss: 0.0300
Epoch 489: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0300
Epoch 490/1000
26/27 [===========================&gt;..] - ETA: 0s - loss: 0.0307
Epoch 490: loss did not improve from 0.00240
27/27 [==============================] - 1s 23ms/step - loss: 0.0333
Epoch 491/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0390
Epoch 491: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0390
Epoch 492/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0266
Epoch 492: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0259
Epoch 493/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0159
Epoch 493: loss did not improve from 0.00240
27/27 [==============================] - 1s 23ms/step - loss: 0.0156
Epoch 494/1000
27/27 [==============================] - ETA: 0s - loss: 0.0162
Epoch 494: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0162
Epoch 495/1000
26/27 [===========================&gt;..] - ETA: 0s - loss: 0.0134
Epoch 495: loss did not improve from 0.00240
27/27 [==============================] - 1s 23ms/step - loss: 0.0142
Epoch 496/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0130
Epoch 496: loss did not improve from 0.00240
27/27 [==============================] - 1s 23ms/step - loss: 0.0124
Epoch 497/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0103
Epoch 497: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0097
Epoch 498/1000
26/27 [===========================&gt;..] - ETA: 0s - loss: 0.0106
Epoch 498: loss did not improve from 0.00240
27/27 [==============================] - 1s 23ms/step - loss: 0.0105
Epoch 499/1000
27/27 [==============================] - ETA: 0s - loss: 0.0085
Epoch 499: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0085
Epoch 500/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0079
Epoch 500: loss did not improve from 0.00240
27/27 [==============================] - 1s 23ms/step - loss: 0.0076
Epoch 501/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0055
Epoch 501: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0054
Epoch 502/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0067
Epoch 502: loss did not improve from 0.00240
27/27 [==============================] - 1s 23ms/step - loss: 0.0067
Epoch 503/1000
27/27 [==============================] - ETA: 0s - loss: 0.0057
Epoch 503: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0057
Epoch 504/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0062
Epoch 504: loss did not improve from 0.00240
27/27 [==============================] - 1s 21ms/step - loss: 0.0062
Epoch 505/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0042
Epoch 505: loss did not improve from 0.00240
27/27 [==============================] - 1s 21ms/step - loss: 0.0044
Epoch 506/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0048
Epoch 506: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0051
Epoch 507/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0062
Epoch 507: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0073
Epoch 508/1000
26/27 [===========================&gt;..] - ETA: 0s - loss: 0.0068
Epoch 508: loss did not improve from 0.00240
27/27 [==============================] - 1s 24ms/step - loss: 0.0067
Epoch 509/1000
27/27 [==============================] - ETA: 0s - loss: 0.0054
Epoch 509: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0054
Epoch 510/1000
27/27 [==============================] - ETA: 0s - loss: 0.0049
Epoch 510: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0049
Epoch 511/1000
26/27 [===========================&gt;..] - ETA: 0s - loss: 0.0044
Epoch 511: loss did not improve from 0.00240
27/27 [==============================] - 1s 23ms/step - loss: 0.0043
Epoch 512/1000
27/27 [==============================] - ETA: 0s - loss: 0.0036
Epoch 512: loss did not improve from 0.00240
27/27 [==============================] - 1s 23ms/step - loss: 0.0036
Epoch 513/1000
26/27 [===========================&gt;..] - ETA: 0s - loss: 0.0042
Epoch 513: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0041
Epoch 514/1000
27/27 [==============================] - ETA: 0s - loss: 0.0038
Epoch 514: loss did not improve from 0.00240
27/27 [==============================] - 1s 23ms/step - loss: 0.0038
Epoch 515/1000
27/27 [==============================] - ETA: 0s - loss: 0.0035
Epoch 515: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0035
Epoch 516/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0037
Epoch 516: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0036
Epoch 517/1000
27/27 [==============================] - ETA: 0s - loss: 0.0043
Epoch 517: loss did not improve from 0.00240
27/27 [==============================] - 1s 23ms/step - loss: 0.0043
Epoch 518/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0039
Epoch 518: loss did not improve from 0.00240
27/27 [==============================] - 1s 23ms/step - loss: 0.0037
Epoch 519/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0035
Epoch 519: loss did not improve from 0.00240
27/27 [==============================] - 1s 23ms/step - loss: 0.0033
Epoch 520/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0024
Epoch 520: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0032
Epoch 521/1000
26/27 [===========================&gt;..] - ETA: 0s - loss: 0.0033
Epoch 521: loss did not improve from 0.00240
27/27 [==============================] - 1s 23ms/step - loss: 0.0033
Epoch 522/1000
26/27 [===========================&gt;..] - ETA: 0s - loss: 0.0036
Epoch 522: loss did not improve from 0.00240
27/27 [==============================] - 1s 23ms/step - loss: 0.0036
Epoch 523/1000
26/27 [===========================&gt;..] - ETA: 0s - loss: 0.0032
Epoch 523: loss did not improve from 0.00240
27/27 [==============================] - 1s 23ms/step - loss: 0.0032
Epoch 524/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0042
Epoch 524: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0041
Epoch 525/1000
27/27 [==============================] - ETA: 0s - loss: 0.0042
Epoch 525: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0042
Epoch 526/1000
27/27 [==============================] - ETA: 0s - loss: 0.0036
Epoch 526: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0036
Epoch 527/1000
26/27 [===========================&gt;..] - ETA: 0s - loss: 0.0031
Epoch 527: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0030
Epoch 528/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0034
Epoch 528: loss did not improve from 0.00240
27/27 [==============================] - 1s 23ms/step - loss: 0.0033
Epoch 529/1000
27/27 [==============================] - ETA: 0s - loss: 0.0038
Epoch 529: loss did not improve from 0.00240
27/27 [==============================] - 1s 23ms/step - loss: 0.0038
Epoch 530/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0067
Epoch 530: loss did not improve from 0.00240
27/27 [==============================] - 1s 23ms/step - loss: 0.0063
Epoch 531/1000
26/27 [===========================&gt;..] - ETA: 0s - loss: 0.0558
Epoch 531: loss did not improve from 0.00240
27/27 [==============================] - 1s 23ms/step - loss: 0.0560
Epoch 532/1000
26/27 [===========================&gt;..] - ETA: 0s - loss: 0.0483
Epoch 532: loss did not improve from 0.00240
27/27 [==============================] - 1s 23ms/step - loss: 0.0478
Epoch 533/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0336
Epoch 533: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0325
Epoch 534/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0149
Epoch 534: loss did not improve from 0.00240
27/27 [==============================] - 1s 23ms/step - loss: 0.0159
Epoch 535/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0135
Epoch 535: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0152
Epoch 536/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0146
Epoch 536: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0144
Epoch 537/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0104
Epoch 537: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0124
Epoch 538/1000
27/27 [==============================] - ETA: 0s - loss: 0.0091
Epoch 538: loss did not improve from 0.00240
27/27 [==============================] - 1s 23ms/step - loss: 0.0091
Epoch 539/1000
26/27 [===========================&gt;..] - ETA: 0s - loss: 0.0081
Epoch 539: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0079
Epoch 540/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0059
Epoch 540: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0069
Epoch 541/1000
27/27 [==============================] - ETA: 0s - loss: 0.0077
Epoch 541: loss did not improve from 0.00240
27/27 [==============================] - 1s 23ms/step - loss: 0.0077
Epoch 542/1000
27/27 [==============================] - ETA: 0s - loss: 0.0106
Epoch 542: loss did not improve from 0.00240
27/27 [==============================] - 1s 23ms/step - loss: 0.0106
Epoch 543/1000
26/27 [===========================&gt;..] - ETA: 0s - loss: 0.0105
Epoch 543: loss did not improve from 0.00240
27/27 [==============================] - 1s 23ms/step - loss: 0.0106
Epoch 544/1000
26/27 [===========================&gt;..] - ETA: 0s - loss: 0.0052
Epoch 544: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0062
Epoch 545/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0083
Epoch 545: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0094
Epoch 546/1000
26/27 [===========================&gt;..] - ETA: 0s - loss: 0.0066
Epoch 546: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0065
Epoch 547/1000
26/27 [===========================&gt;..] - ETA: 0s - loss: 0.0058
Epoch 547: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0057
Epoch 548/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0042
Epoch 548: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0046
Epoch 549/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0031
Epoch 549: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0043
Epoch 550/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0042
Epoch 550: loss did not improve from 0.00240
27/27 [==============================] - 1s 21ms/step - loss: 0.0040
Epoch 551/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0038
Epoch 551: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0036
Epoch 552/1000
27/27 [==============================] - ETA: 0s - loss: 0.0041
Epoch 552: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0041
Epoch 553/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0037
Epoch 553: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0035
Epoch 554/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0039
Epoch 554: loss did not improve from 0.00240
27/27 [==============================] - 1s 23ms/step - loss: 0.0037
Epoch 555/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0036
Epoch 555: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0036
Epoch 556/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0030
Epoch 556: loss did not improve from 0.00240
27/27 [==============================] - 1s 23ms/step - loss: 0.0040
Epoch 557/1000
27/27 [==============================] - ETA: 0s - loss: 0.0035
Epoch 557: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0035
Epoch 558/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0043
Epoch 558: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0040
Epoch 559/1000
26/27 [===========================&gt;..] - ETA: 0s - loss: 0.0042
Epoch 559: loss did not improve from 0.00240
27/27 [==============================] - 1s 23ms/step - loss: 0.0041
Epoch 560/1000
26/27 [===========================&gt;..] - ETA: 0s - loss: 0.0043
Epoch 560: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0043
Epoch 561/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0033
Epoch 561: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0032
Epoch 562/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0035
Epoch 562: loss did not improve from 0.00240
27/27 [==============================] - 1s 23ms/step - loss: 0.0033
Epoch 563/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0036
Epoch 563: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0041
Epoch 564/1000
27/27 [==============================] - ETA: 0s - loss: 0.0037
Epoch 564: loss did not improve from 0.00240
27/27 [==============================] - 1s 23ms/step - loss: 0.0037
Epoch 565/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0040
Epoch 565: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0038
Epoch 566/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0034
Epoch 566: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0038
Epoch 567/1000
26/27 [===========================&gt;..] - ETA: 0s - loss: 0.0040
Epoch 567: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0040
Epoch 568/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0036
Epoch 568: loss did not improve from 0.00240
27/27 [==============================] - 1s 21ms/step - loss: 0.0036
Epoch 569/1000
26/27 [===========================&gt;..] - ETA: 0s - loss: 0.0039
Epoch 569: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0039
Epoch 570/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0146
Epoch 570: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0161
Epoch 571/1000
27/27 [==============================] - ETA: 0s - loss: 0.0129
Epoch 571: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0129
Epoch 572/1000
26/27 [===========================&gt;..] - ETA: 0s - loss: 0.0211
Epoch 572: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0206
Epoch 573/1000
26/27 [===========================&gt;..] - ETA: 0s - loss: 0.0320
Epoch 573: loss did not improve from 0.00240
27/27 [==============================] - 1s 23ms/step - loss: 0.0313
Epoch 574/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0248
Epoch 574: loss did not improve from 0.00240
27/27 [==============================] - 1s 23ms/step - loss: 0.0238
Epoch 575/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0154
Epoch 575: loss did not improve from 0.00240
27/27 [==============================] - 1s 21ms/step - loss: 0.0149
Epoch 576/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0172
Epoch 576: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0175
Epoch 577/1000
27/27 [==============================] - ETA: 0s - loss: 0.0090
Epoch 577: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0090
Epoch 578/1000
27/27 [==============================] - ETA: 0s - loss: 0.0079
Epoch 578: loss did not improve from 0.00240
27/27 [==============================] - 1s 23ms/step - loss: 0.0079
Epoch 579/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0075
Epoch 579: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0072
Epoch 580/1000
27/27 [==============================] - ETA: 0s - loss: 0.0062
Epoch 580: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0062
Epoch 581/1000
26/27 [===========================&gt;..] - ETA: 0s - loss: 0.0091
Epoch 581: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0089
Epoch 582/1000
27/27 [==============================] - ETA: 0s - loss: 0.0080
Epoch 582: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0080
Epoch 583/1000
26/27 [===========================&gt;..] - ETA: 0s - loss: 0.0051
Epoch 583: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0050
Epoch 584/1000
26/27 [===========================&gt;..] - ETA: 0s - loss: 0.0048
Epoch 584: loss did not improve from 0.00240
27/27 [==============================] - 1s 23ms/step - loss: 0.0046
Epoch 585/1000
26/27 [===========================&gt;..] - ETA: 0s - loss: 0.0043
Epoch 585: loss did not improve from 0.00240
27/27 [==============================] - 1s 23ms/step - loss: 0.0042
Epoch 586/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0036
Epoch 586: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0035
Epoch 587/1000
27/27 [==============================] - ETA: 0s - loss: 0.0035
Epoch 587: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0035
Epoch 588/1000
27/27 [==============================] - ETA: 0s - loss: 0.0037
Epoch 588: loss did not improve from 0.00240
27/27 [==============================] - 1s 23ms/step - loss: 0.0037
Epoch 589/1000
26/27 [===========================&gt;..] - ETA: 0s - loss: 0.0032
Epoch 589: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0032
Epoch 590/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0022
Epoch 590: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0036
Epoch 591/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0025
Epoch 591: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0040
Epoch 592/1000
27/27 [==============================] - ETA: 0s - loss: 0.0036
Epoch 592: loss did not improve from 0.00240
27/27 [==============================] - 1s 23ms/step - loss: 0.0036
Epoch 593/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0036
Epoch 593: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0034
Epoch 594/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0040
Epoch 594: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0037
Epoch 595/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0036
Epoch 595: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0034
Epoch 596/1000
27/27 [==============================] - ETA: 0s - loss: 0.0034
Epoch 596: loss did not improve from 0.00240
27/27 [==============================] - 1s 23ms/step - loss: 0.0034
Epoch 597/1000
27/27 [==============================] - ETA: 0s - loss: 0.0034
Epoch 597: loss did not improve from 0.00240
27/27 [==============================] - 1s 23ms/step - loss: 0.0034
Epoch 598/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0037
Epoch 598: loss did not improve from 0.00240
27/27 [==============================] - 1s 23ms/step - loss: 0.0035
Epoch 599/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0035
Epoch 599: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0033
Epoch 600/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0039
Epoch 600: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0037
Epoch 601/1000
27/27 [==============================] - ETA: 0s - loss: 0.0033
Epoch 601: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0033
Epoch 602/1000
27/27 [==============================] - ETA: 0s - loss: 0.0035
Epoch 602: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0035
Epoch 603/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0031
Epoch 603: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0033
Epoch 604/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0030
Epoch 604: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0029
Epoch 605/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0024
Epoch 605: loss did not improve from 0.00240
27/27 [==============================] - 1s 21ms/step - loss: 0.0027
Epoch 606/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0043
Epoch 606: loss did not improve from 0.00240
27/27 [==============================] - 1s 21ms/step - loss: 0.0041
Epoch 607/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0033
Epoch 607: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0032
Epoch 608/1000
26/27 [===========================&gt;..] - ETA: 0s - loss: 0.0031
Epoch 608: loss did not improve from 0.00240
27/27 [==============================] - 1s 23ms/step - loss: 0.0030
Epoch 609/1000
26/27 [===========================&gt;..] - ETA: 0s - loss: 0.0032
Epoch 609: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0031
Epoch 610/1000
27/27 [==============================] - ETA: 0s - loss: 0.0031
Epoch 610: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0031
Epoch 611/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0034
Epoch 611: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0032
Epoch 612/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0035
Epoch 612: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0033
Epoch 613/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0038
Epoch 613: loss did not improve from 0.00240
27/27 [==============================] - 1s 23ms/step - loss: 0.0036
Epoch 614/1000
27/27 [==============================] - ETA: 0s - loss: 0.0032
Epoch 614: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0032
Epoch 615/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0034
Epoch 615: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0032
Epoch 616/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0028
Epoch 616: loss did not improve from 0.00240
27/27 [==============================] - 1s 21ms/step - loss: 0.0028
Epoch 617/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0032
Epoch 617: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0031
Epoch 618/1000
26/27 [===========================&gt;..] - ETA: 0s - loss: 0.0031
Epoch 618: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0031
Epoch 619/1000
27/27 [==============================] - ETA: 0s - loss: 0.0039
Epoch 619: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0039
Epoch 620/1000
27/27 [==============================] - ETA: 0s - loss: 0.0030
Epoch 620: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0030
Epoch 621/1000
27/27 [==============================] - ETA: 0s - loss: 0.0035
Epoch 621: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0035
Epoch 622/1000
27/27 [==============================] - ETA: 0s - loss: 0.0031
Epoch 622: loss did not improve from 0.00240
27/27 [==============================] - 1s 23ms/step - loss: 0.0031
Epoch 623/1000
27/27 [==============================] - ETA: 0s - loss: 0.0030
Epoch 623: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0030
Epoch 624/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0025
Epoch 624: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0026
Epoch 625/1000
26/27 [===========================&gt;..] - ETA: 0s - loss: 0.0031
Epoch 625: loss did not improve from 0.00240
27/27 [==============================] - 1s 23ms/step - loss: 0.0034
Epoch 626/1000
27/27 [==============================] - ETA: 0s - loss: 0.0030
Epoch 626: loss did not improve from 0.00240
27/27 [==============================] - 1s 23ms/step - loss: 0.0030
Epoch 627/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0038
Epoch 627: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0036
Epoch 628/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0032
Epoch 628: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0030
Epoch 629/1000
27/27 [==============================] - ETA: 0s - loss: 0.0027
Epoch 629: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0027
Epoch 630/1000
27/27 [==============================] - ETA: 0s - loss: 0.0033
Epoch 630: loss did not improve from 0.00240
27/27 [==============================] - 1s 23ms/step - loss: 0.0033
Epoch 631/1000
27/27 [==============================] - ETA: 0s - loss: 0.0032
Epoch 631: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0032
Epoch 632/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0033
Epoch 632: loss did not improve from 0.00240
27/27 [==============================] - 1s 21ms/step - loss: 0.0033
Epoch 633/1000
26/27 [===========================&gt;..] - ETA: 0s - loss: 0.0032
Epoch 633: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0031
Epoch 634/1000
26/27 [===========================&gt;..] - ETA: 0s - loss: 0.0033
Epoch 634: loss did not improve from 0.00240
27/27 [==============================] - 1s 23ms/step - loss: 0.0032
Epoch 635/1000
26/27 [===========================&gt;..] - ETA: 0s - loss: 0.0039
Epoch 635: loss did not improve from 0.00240
27/27 [==============================] - 1s 23ms/step - loss: 0.0038
Epoch 636/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0032
Epoch 636: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0032
Epoch 637/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0205
Epoch 637: loss did not improve from 0.00240
27/27 [==============================] - 1s 21ms/step - loss: 0.0217
Epoch 638/1000
27/27 [==============================] - ETA: 0s - loss: 0.0847
Epoch 638: loss did not improve from 0.00240
27/27 [==============================] - 1s 23ms/step - loss: 0.0847
Epoch 639/1000
27/27 [==============================] - ETA: 0s - loss: 0.0564
Epoch 639: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0564
Epoch 640/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0422
Epoch 640: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0424
Epoch 641/1000
27/27 [==============================] - ETA: 0s - loss: 0.0224
Epoch 641: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0224
Epoch 642/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0132
Epoch 642: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0144
Epoch 643/1000
26/27 [===========================&gt;..] - ETA: 0s - loss: 0.0178
Epoch 643: loss did not improve from 0.00240
27/27 [==============================] - 1s 23ms/step - loss: 0.0174
Epoch 644/1000
27/27 [==============================] - ETA: 0s - loss: 0.0147
Epoch 644: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0147
Epoch 645/1000
27/27 [==============================] - ETA: 0s - loss: 0.0144
Epoch 645: loss did not improve from 0.00240
27/27 [==============================] - 1s 23ms/step - loss: 0.0144
Epoch 646/1000
26/27 [===========================&gt;..] - ETA: 0s - loss: 0.0123
Epoch 646: loss did not improve from 0.00240
27/27 [==============================] - 1s 23ms/step - loss: 0.0121
Epoch 647/1000
27/27 [==============================] - ETA: 0s - loss: 0.0079
Epoch 647: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0079
Epoch 648/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0252
Epoch 648: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0268
Epoch 649/1000
27/27 [==============================] - ETA: 0s - loss: 0.0234
Epoch 649: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0234
Epoch 650/1000
26/27 [===========================&gt;..] - ETA: 0s - loss: 0.0213
Epoch 650: loss did not improve from 0.00240
27/27 [==============================] - 1s 23ms/step - loss: 0.0208
Epoch 651/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0349
Epoch 651: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0339
Epoch 652/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.2422
Epoch 652: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.2338
Epoch 653/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.1550
Epoch 653: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.1492
Epoch 654/1000
27/27 [==============================] - ETA: 0s - loss: 0.0767
Epoch 654: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0767
Epoch 655/1000
26/27 [===========================&gt;..] - ETA: 0s - loss: 0.0494
Epoch 655: loss did not improve from 0.00240
27/27 [==============================] - 1s 23ms/step - loss: 0.0495
Epoch 656/1000
27/27 [==============================] - ETA: 0s - loss: 0.0324
Epoch 656: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0324
Epoch 657/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0265
Epoch 657: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0252
Epoch 658/1000
27/27 [==============================] - ETA: 0s - loss: 0.0194
Epoch 658: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0194
Epoch 659/1000
27/27 [==============================] - ETA: 0s - loss: 0.0169
Epoch 659: loss did not improve from 0.00240
27/27 [==============================] - 1s 23ms/step - loss: 0.0169
Epoch 660/1000
26/27 [===========================&gt;..] - ETA: 0s - loss: 0.0142
Epoch 660: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0143
Epoch 661/1000
27/27 [==============================] - ETA: 0s - loss: 0.0129
Epoch 661: loss did not improve from 0.00240
27/27 [==============================] - 1s 23ms/step - loss: 0.0129
Epoch 662/1000
27/27 [==============================] - ETA: 0s - loss: 0.0118
Epoch 662: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0118
Epoch 663/1000
26/27 [===========================&gt;..] - ETA: 0s - loss: 0.0120
Epoch 663: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0117
Epoch 664/1000
26/27 [===========================&gt;..] - ETA: 0s - loss: 0.0158
Epoch 664: loss did not improve from 0.00240
27/27 [==============================] - 1s 23ms/step - loss: 0.0158
Epoch 665/1000
27/27 [==============================] - ETA: 0s - loss: 0.0190
Epoch 665: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0190
Epoch 666/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0184
Epoch 666: loss did not improve from 0.00240
27/27 [==============================] - 1s 23ms/step - loss: 0.0176
Epoch 667/1000
26/27 [===========================&gt;..] - ETA: 0s - loss: 0.0118
Epoch 667: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0132
Epoch 668/1000
26/27 [===========================&gt;..] - ETA: 0s - loss: 0.0129
Epoch 668: loss did not improve from 0.00240
27/27 [==============================] - 1s 23ms/step - loss: 0.0126
Epoch 669/1000
27/27 [==============================] - ETA: 0s - loss: 0.0090
Epoch 669: loss did not improve from 0.00240
27/27 [==============================] - 1s 23ms/step - loss: 0.0090
Epoch 670/1000
27/27 [==============================] - ETA: 0s - loss: 0.0090
Epoch 670: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0090
Epoch 671/1000
26/27 [===========================&gt;..] - ETA: 0s - loss: 0.0070
Epoch 671: loss did not improve from 0.00240
27/27 [==============================] - 1s 23ms/step - loss: 0.0068
Epoch 672/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0069
Epoch 672: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0069
Epoch 673/1000
27/27 [==============================] - ETA: 0s - loss: 0.0060
Epoch 673: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0060
Epoch 674/1000
27/27 [==============================] - ETA: 0s - loss: 0.0068
Epoch 674: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0068
Epoch 675/1000
27/27 [==============================] - ETA: 0s - loss: 0.0068
Epoch 675: loss did not improve from 0.00240
27/27 [==============================] - 1s 23ms/step - loss: 0.0068
Epoch 676/1000
27/27 [==============================] - ETA: 0s - loss: 0.0054
Epoch 676: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0054
Epoch 677/1000
27/27 [==============================] - ETA: 0s - loss: 0.0051
Epoch 677: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0051
Epoch 678/1000
26/27 [===========================&gt;..] - ETA: 0s - loss: 0.0047
Epoch 678: loss did not improve from 0.00240
27/27 [==============================] - 1s 23ms/step - loss: 0.0046
Epoch 679/1000
26/27 [===========================&gt;..] - ETA: 0s - loss: 0.0057
Epoch 679: loss did not improve from 0.00240
27/27 [==============================] - 1s 23ms/step - loss: 0.0057
Epoch 680/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0053
Epoch 680: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0054
Epoch 681/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0044
Epoch 681: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0043
Epoch 682/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0055
Epoch 682: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0052
Epoch 683/1000
27/27 [==============================] - ETA: 0s - loss: 0.0046
Epoch 683: loss did not improve from 0.00240
27/27 [==============================] - 1s 23ms/step - loss: 0.0046
Epoch 684/1000
27/27 [==============================] - ETA: 0s - loss: 0.0042
Epoch 684: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0042
Epoch 685/1000
27/27 [==============================] - ETA: 0s - loss: 0.0046
Epoch 685: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0046
Epoch 686/1000
27/27 [==============================] - ETA: 0s - loss: 0.0040
Epoch 686: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0040
Epoch 687/1000
27/27 [==============================] - ETA: 0s - loss: 0.0045
Epoch 687: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0045
Epoch 688/1000
26/27 [===========================&gt;..] - ETA: 0s - loss: 0.0041
Epoch 688: loss did not improve from 0.00240
27/27 [==============================] - 1s 23ms/step - loss: 0.0040
Epoch 689/1000
27/27 [==============================] - ETA: 0s - loss: 0.0046
Epoch 689: loss did not improve from 0.00240
27/27 [==============================] - 1s 23ms/step - loss: 0.0046
Epoch 690/1000
27/27 [==============================] - ETA: 0s - loss: 0.0058
Epoch 690: loss did not improve from 0.00240
27/27 [==============================] - 1s 21ms/step - loss: 0.0058
Epoch 691/1000
27/27 [==============================] - ETA: 0s - loss: 0.0050
Epoch 691: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0050
Epoch 692/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0043
Epoch 692: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0041
Epoch 693/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0036
Epoch 693: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0036
Epoch 694/1000
26/27 [===========================&gt;..] - ETA: 0s - loss: 0.0043
Epoch 694: loss did not improve from 0.00240
27/27 [==============================] - 1s 23ms/step - loss: 0.0042
Epoch 695/1000
27/27 [==============================] - ETA: 0s - loss: 0.0041
Epoch 695: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0041
Epoch 696/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0033
Epoch 696: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0034
Epoch 697/1000
26/27 [===========================&gt;..] - ETA: 0s - loss: 0.0143
Epoch 697: loss did not improve from 0.00240
27/27 [==============================] - 1s 23ms/step - loss: 0.0142
Epoch 698/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0304
Epoch 698: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0301
Epoch 699/1000
27/27 [==============================] - ETA: 0s - loss: 0.0192
Epoch 699: loss did not improve from 0.00240
27/27 [==============================] - 1s 23ms/step - loss: 0.0192
Epoch 700/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0227
Epoch 700: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0218
Epoch 701/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0134
Epoch 701: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0127
Epoch 702/1000
27/27 [==============================] - ETA: 0s - loss: 0.0086
Epoch 702: loss did not improve from 0.00240
27/27 [==============================] - 1s 23ms/step - loss: 0.0086
Epoch 703/1000
27/27 [==============================] - ETA: 0s - loss: 0.0054
Epoch 703: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0054
Epoch 704/1000
26/27 [===========================&gt;..] - ETA: 0s - loss: 0.0052
Epoch 704: loss did not improve from 0.00240
27/27 [==============================] - 1s 23ms/step - loss: 0.0051
Epoch 705/1000
27/27 [==============================] - ETA: 0s - loss: 0.0051
Epoch 705: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0051
Epoch 706/1000
27/27 [==============================] - ETA: 0s - loss: 0.0049
Epoch 706: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0049
Epoch 707/1000
26/27 [===========================&gt;..] - ETA: 0s - loss: 0.0043
Epoch 707: loss did not improve from 0.00240
27/27 [==============================] - 1s 23ms/step - loss: 0.0043
Epoch 708/1000
27/27 [==============================] - ETA: 0s - loss: 0.0048
Epoch 708: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0048
Epoch 709/1000
27/27 [==============================] - ETA: 0s - loss: 0.0040
Epoch 709: loss did not improve from 0.00240
27/27 [==============================] - 1s 23ms/step - loss: 0.0040
Epoch 710/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0036
Epoch 710: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0035
Epoch 711/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0046
Epoch 711: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0043
Epoch 712/1000
26/27 [===========================&gt;..] - ETA: 0s - loss: 0.0053
Epoch 712: loss did not improve from 0.00240
27/27 [==============================] - 1s 23ms/step - loss: 0.0052
Epoch 713/1000
27/27 [==============================] - ETA: 0s - loss: 0.0038
Epoch 713: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0038
Epoch 714/1000
27/27 [==============================] - ETA: 0s - loss: 0.0037
Epoch 714: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0037
Epoch 715/1000
27/27 [==============================] - ETA: 0s - loss: 0.0042
Epoch 715: loss did not improve from 0.00240
27/27 [==============================] - 1s 23ms/step - loss: 0.0042
Epoch 716/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0034
Epoch 716: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0042
Epoch 717/1000
26/27 [===========================&gt;..] - ETA: 0s - loss: 0.0038
Epoch 717: loss did not improve from 0.00240
27/27 [==============================] - 1s 23ms/step - loss: 0.0039
Epoch 718/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0035
Epoch 718: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0033
Epoch 719/1000
27/27 [==============================] - ETA: 0s - loss: 0.0045
Epoch 719: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0045
Epoch 720/1000
26/27 [===========================&gt;..] - ETA: 0s - loss: 0.0037
Epoch 720: loss did not improve from 0.00240
27/27 [==============================] - 1s 23ms/step - loss: 0.0036
Epoch 721/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0028
Epoch 721: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0037
Epoch 722/1000
26/27 [===========================&gt;..] - ETA: 0s - loss: 0.0043
Epoch 722: loss did not improve from 0.00240
27/27 [==============================] - 1s 23ms/step - loss: 0.0042
Epoch 723/1000
27/27 [==============================] - ETA: 0s - loss: 0.0042
Epoch 723: loss did not improve from 0.00240
27/27 [==============================] - 1s 23ms/step - loss: 0.0042
Epoch 724/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0036
Epoch 724: loss did not improve from 0.00240
27/27 [==============================] - 1s 23ms/step - loss: 0.0035
Epoch 725/1000
26/27 [===========================&gt;..] - ETA: 0s - loss: 0.0035
Epoch 725: loss did not improve from 0.00240
27/27 [==============================] - 1s 23ms/step - loss: 0.0034
Epoch 726/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0035
Epoch 726: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0038
Epoch 727/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0038
Epoch 727: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0036
Epoch 728/1000
27/27 [==============================] - ETA: 0s - loss: 0.0039
Epoch 728: loss did not improve from 0.00240
27/27 [==============================] - 1s 23ms/step - loss: 0.0039
Epoch 729/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0042
Epoch 729: loss did not improve from 0.00240
27/27 [==============================] - 1s 24ms/step - loss: 0.0040
Epoch 730/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0030
Epoch 730: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0039
Epoch 731/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0042
Epoch 731: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0040
Epoch 732/1000
26/27 [===========================&gt;..] - ETA: 0s - loss: 0.0038
Epoch 732: loss did not improve from 0.00240
27/27 [==============================] - 1s 23ms/step - loss: 0.0037
Epoch 733/1000
26/27 [===========================&gt;..] - ETA: 0s - loss: 0.0035
Epoch 733: loss did not improve from 0.00240
27/27 [==============================] - 1s 23ms/step - loss: 0.0034
Epoch 734/1000
26/27 [===========================&gt;..] - ETA: 0s - loss: 0.0019
Epoch 734: loss did not improve from 0.00240
27/27 [==============================] - 1s 23ms/step - loss: 0.0030
Epoch 735/1000
27/27 [==============================] - ETA: 0s - loss: 0.0040
Epoch 735: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0040
Epoch 736/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0034
Epoch 736: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0032
Epoch 737/1000
27/27 [==============================] - ETA: 0s - loss: 0.0039
Epoch 737: loss did not improve from 0.00240
27/27 [==============================] - 1s 23ms/step - loss: 0.0039
Epoch 738/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0041
Epoch 738: loss did not improve from 0.00240
27/27 [==============================] - 1s 21ms/step - loss: 0.0039
Epoch 739/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0041
Epoch 739: loss did not improve from 0.00240
27/27 [==============================] - 1s 21ms/step - loss: 0.0039
Epoch 740/1000
27/27 [==============================] - ETA: 0s - loss: 0.0033
Epoch 740: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0033
Epoch 741/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0033
Epoch 741: loss did not improve from 0.00240
27/27 [==============================] - 1s 21ms/step - loss: 0.0031
Epoch 742/1000
26/27 [===========================&gt;..] - ETA: 0s - loss: 0.0040
Epoch 742: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0039
Epoch 743/1000
26/27 [===========================&gt;..] - ETA: 0s - loss: 0.0035
Epoch 743: loss did not improve from 0.00240
27/27 [==============================] - 1s 23ms/step - loss: 0.0034
Epoch 744/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0034
Epoch 744: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0035
Epoch 745/1000
27/27 [==============================] - ETA: 0s - loss: 0.0040
Epoch 745: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0040
Epoch 746/1000
27/27 [==============================] - ETA: 0s - loss: 0.0040
Epoch 746: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0040
Epoch 747/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0035
Epoch 747: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0037
Epoch 748/1000
27/27 [==============================] - ETA: 0s - loss: 0.0513
Epoch 748: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0513
Epoch 749/1000
27/27 [==============================] - ETA: 0s - loss: 0.1126
Epoch 749: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.1126
Epoch 750/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0597
Epoch 750: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0616
Epoch 751/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0352
Epoch 751: loss did not improve from 0.00240
27/27 [==============================] - 1s 21ms/step - loss: 0.0345
Epoch 752/1000
27/27 [==============================] - ETA: 0s - loss: 0.0298
Epoch 752: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0298
Epoch 753/1000
27/27 [==============================] - ETA: 0s - loss: 0.0323
Epoch 753: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0323
Epoch 754/1000
27/27 [==============================] - ETA: 0s - loss: 0.0343
Epoch 754: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0343
Epoch 755/1000
27/27 [==============================] - ETA: 0s - loss: 0.0263
Epoch 755: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0263
Epoch 756/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0218
Epoch 756: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0231
Epoch 757/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0162
Epoch 757: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0169
Epoch 758/1000
27/27 [==============================] - ETA: 0s - loss: 0.0141
Epoch 758: loss did not improve from 0.00240
27/27 [==============================] - 1s 23ms/step - loss: 0.0141
Epoch 759/1000
26/27 [===========================&gt;..] - ETA: 0s - loss: 0.0109
Epoch 759: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0108
Epoch 760/1000
27/27 [==============================] - ETA: 0s - loss: 0.0105
Epoch 760: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0105
Epoch 761/1000
27/27 [==============================] - ETA: 0s - loss: 0.0090
Epoch 761: loss did not improve from 0.00240
27/27 [==============================] - 1s 23ms/step - loss: 0.0090
Epoch 762/1000
26/27 [===========================&gt;..] - ETA: 0s - loss: 0.0101
Epoch 762: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0099
Epoch 763/1000
26/27 [===========================&gt;..] - ETA: 0s - loss: 0.0078
Epoch 763: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0076
Epoch 764/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0066
Epoch 764: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0062
Epoch 765/1000
26/27 [===========================&gt;..] - ETA: 0s - loss: 0.0056
Epoch 765: loss did not improve from 0.00240
27/27 [==============================] - 1s 23ms/step - loss: 0.0055
Epoch 766/1000
26/27 [===========================&gt;..] - ETA: 0s - loss: 0.0053
Epoch 766: loss did not improve from 0.00240
27/27 [==============================] - 1s 23ms/step - loss: 0.0054
Epoch 767/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0033
Epoch 767: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0060
Epoch 768/1000
27/27 [==============================] - ETA: 0s - loss: 0.0047
Epoch 768: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0047
Epoch 769/1000
26/27 [===========================&gt;..] - ETA: 0s - loss: 0.0047
Epoch 769: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0046
Epoch 770/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0060
Epoch 770: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0056
Epoch 771/1000
27/27 [==============================] - ETA: 0s - loss: 0.0045
Epoch 771: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0045
Epoch 772/1000
27/27 [==============================] - ETA: 0s - loss: 0.0045
Epoch 772: loss did not improve from 0.00240
27/27 [==============================] - 1s 23ms/step - loss: 0.0045
Epoch 773/1000
27/27 [==============================] - ETA: 0s - loss: 0.0047
Epoch 773: loss did not improve from 0.00240
27/27 [==============================] - 1s 23ms/step - loss: 0.0047
Epoch 774/1000
27/27 [==============================] - ETA: 0s - loss: 0.0064
Epoch 774: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0064
Epoch 775/1000
27/27 [==============================] - ETA: 0s - loss: 0.0056
Epoch 775: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0056
Epoch 776/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0050
Epoch 776: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0061
Epoch 777/1000
27/27 [==============================] - ETA: 0s - loss: 0.0073
Epoch 777: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0073
Epoch 778/1000
26/27 [===========================&gt;..] - ETA: 0s - loss: 0.0347
Epoch 778: loss did not improve from 0.00240
27/27 [==============================] - 1s 23ms/step - loss: 0.0338
Epoch 779/1000
26/27 [===========================&gt;..] - ETA: 0s - loss: 0.0233
Epoch 779: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0243
Epoch 780/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0141
Epoch 780: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0134
Epoch 781/1000
26/27 [===========================&gt;..] - ETA: 0s - loss: 0.0075
Epoch 781: loss did not improve from 0.00240
27/27 [==============================] - 1s 23ms/step - loss: 0.0076
Epoch 782/1000
26/27 [===========================&gt;..] - ETA: 0s - loss: 0.0070
Epoch 782: loss did not improve from 0.00240
27/27 [==============================] - 1s 23ms/step - loss: 0.0068
Epoch 783/1000
26/27 [===========================&gt;..] - ETA: 0s - loss: 0.0057
Epoch 783: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0057
Epoch 784/1000
27/27 [==============================] - ETA: 0s - loss: 0.0153
Epoch 784: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0153
Epoch 785/1000
27/27 [==============================] - ETA: 0s - loss: 0.0176
Epoch 785: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0176
Epoch 786/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0089
Epoch 786: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0099
Epoch 787/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0108
Epoch 787: loss did not improve from 0.00240
27/27 [==============================] - 1s 21ms/step - loss: 0.0105
Epoch 788/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0111
Epoch 788: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0106
Epoch 789/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0078
Epoch 789: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0077
Epoch 790/1000
27/27 [==============================] - ETA: 0s - loss: 0.0057
Epoch 790: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0057
Epoch 791/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0049
Epoch 791: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0047
Epoch 792/1000
27/27 [==============================] - ETA: 0s - loss: 0.0044
Epoch 792: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0044
Epoch 793/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0052
Epoch 793: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0049
Epoch 794/1000
26/27 [===========================&gt;..] - ETA: 0s - loss: 0.0054
Epoch 794: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0053
Epoch 795/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0087
Epoch 795: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0091
Epoch 796/1000
26/27 [===========================&gt;..] - ETA: 0s - loss: 0.0065
Epoch 796: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0063
Epoch 797/1000
27/27 [==============================] - ETA: 0s - loss: 0.0099
Epoch 797: loss did not improve from 0.00240
27/27 [==============================] - 1s 23ms/step - loss: 0.0099
Epoch 798/1000
27/27 [==============================] - ETA: 0s - loss: 0.0119
Epoch 798: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0119
Epoch 799/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0089
Epoch 799: loss did not improve from 0.00240
27/27 [==============================] - 1s 23ms/step - loss: 0.0092
Epoch 800/1000
26/27 [===========================&gt;..] - ETA: 0s - loss: 0.0049
Epoch 800: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0049
Epoch 801/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0045
Epoch 801: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0043
Epoch 802/1000
26/27 [===========================&gt;..] - ETA: 0s - loss: 0.0038
Epoch 802: loss did not improve from 0.00240
27/27 [==============================] - 1s 23ms/step - loss: 0.0038
Epoch 803/1000
27/27 [==============================] - ETA: 0s - loss: 0.0032
Epoch 803: loss did not improve from 0.00240
27/27 [==============================] - 1s 23ms/step - loss: 0.0032
Epoch 804/1000
27/27 [==============================] - ETA: 0s - loss: 0.0041
Epoch 804: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0041
Epoch 805/1000
27/27 [==============================] - ETA: 0s - loss: 0.0039
Epoch 805: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0039
Epoch 806/1000
27/27 [==============================] - ETA: 0s - loss: 0.0033
Epoch 806: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0033
Epoch 807/1000
26/27 [===========================&gt;..] - ETA: 0s - loss: 0.0035
Epoch 807: loss did not improve from 0.00240
27/27 [==============================] - 1s 23ms/step - loss: 0.0034
Epoch 808/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0038
Epoch 808: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0036
Epoch 809/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0037
Epoch 809: loss did not improve from 0.00240
27/27 [==============================] - 1s 21ms/step - loss: 0.0035
Epoch 810/1000
26/27 [===========================&gt;..] - ETA: 0s - loss: 0.0039
Epoch 810: loss did not improve from 0.00240
27/27 [==============================] - 1s 23ms/step - loss: 0.0038
Epoch 811/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0039
Epoch 811: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0037
Epoch 812/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0034
Epoch 812: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0033
Epoch 813/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0034
Epoch 813: loss did not improve from 0.00240
27/27 [==============================] - 1s 23ms/step - loss: 0.0032
Epoch 814/1000
27/27 [==============================] - ETA: 0s - loss: 0.0027
Epoch 814: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0027
Epoch 815/1000
26/27 [===========================&gt;..] - ETA: 0s - loss: 0.0034
Epoch 815: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0033
Epoch 816/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0039
Epoch 816: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0037
Epoch 817/1000
26/27 [===========================&gt;..] - ETA: 0s - loss: 0.0024
Epoch 817: loss did not improve from 0.00240
27/27 [==============================] - 1s 23ms/step - loss: 0.0037
Epoch 818/1000
26/27 [===========================&gt;..] - ETA: 0s - loss: 0.0031
Epoch 818: loss did not improve from 0.00240
27/27 [==============================] - 1s 23ms/step - loss: 0.0030
Epoch 819/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0030
Epoch 819: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0029
Epoch 820/1000
26/27 [===========================&gt;..] - ETA: 0s - loss: 0.0028
Epoch 820: loss did not improve from 0.00240
27/27 [==============================] - 1s 23ms/step - loss: 0.0027
Epoch 821/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0042
Epoch 821: loss did not improve from 0.00240
27/27 [==============================] - 1s 23ms/step - loss: 0.0040
Epoch 822/1000
27/27 [==============================] - ETA: 0s - loss: 0.0037
Epoch 822: loss did not improve from 0.00240
27/27 [==============================] - 1s 24ms/step - loss: 0.0037
Epoch 823/1000
27/27 [==============================] - ETA: 0s - loss: 0.0050
Epoch 823: loss did not improve from 0.00240
27/27 [==============================] - 1s 23ms/step - loss: 0.0050
Epoch 824/1000
26/27 [===========================&gt;..] - ETA: 0s - loss: 0.0096
Epoch 824: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0109
Epoch 825/1000
26/27 [===========================&gt;..] - ETA: 0s - loss: 0.0091
Epoch 825: loss did not improve from 0.00240
27/27 [==============================] - 1s 23ms/step - loss: 0.0089
Epoch 826/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0091
Epoch 826: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0095
Epoch 827/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0117
Epoch 827: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0113
Epoch 828/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0082
Epoch 828: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0097
Epoch 829/1000
27/27 [==============================] - ETA: 0s - loss: 0.0593
Epoch 829: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0593
Epoch 830/1000
27/27 [==============================] - ETA: 0s - loss: 0.0227
Epoch 830: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0227
Epoch 831/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0164
Epoch 831: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0163
Epoch 832/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0125
Epoch 832: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0119
Epoch 833/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0069
Epoch 833: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0082
Epoch 834/1000
27/27 [==============================] - ETA: 0s - loss: 0.0064
Epoch 834: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0064
Epoch 835/1000
26/27 [===========================&gt;..] - ETA: 0s - loss: 0.0066
Epoch 835: loss did not improve from 0.00240
27/27 [==============================] - 1s 23ms/step - loss: 0.0064
Epoch 836/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0049
Epoch 836: loss did not improve from 0.00240
27/27 [==============================] - 1s 23ms/step - loss: 0.0062
Epoch 837/1000
26/27 [===========================&gt;..] - ETA: 0s - loss: 0.0041
Epoch 837: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0056
Epoch 838/1000
27/27 [==============================] - ETA: 0s - loss: 0.0050
Epoch 838: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0050
Epoch 839/1000
26/27 [===========================&gt;..] - ETA: 0s - loss: 0.0037
Epoch 839: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0048
Epoch 840/1000
26/27 [===========================&gt;..] - ETA: 0s - loss: 0.0043
Epoch 840: loss did not improve from 0.00240
27/27 [==============================] - 1s 23ms/step - loss: 0.0046
Epoch 841/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0040
Epoch 841: loss did not improve from 0.00240
27/27 [==============================] - 1s 23ms/step - loss: 0.0040
Epoch 842/1000
27/27 [==============================] - ETA: 0s - loss: 0.0045
Epoch 842: loss did not improve from 0.00240
27/27 [==============================] - 1s 23ms/step - loss: 0.0045
Epoch 843/1000
26/27 [===========================&gt;..] - ETA: 0s - loss: 0.0041
Epoch 843: loss did not improve from 0.00240
27/27 [==============================] - 1s 23ms/step - loss: 0.0041
Epoch 844/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0048
Epoch 844: loss did not improve from 0.00240
27/27 [==============================] - 1s 23ms/step - loss: 0.0049
Epoch 845/1000
27/27 [==============================] - ETA: 0s - loss: 0.0060
Epoch 845: loss did not improve from 0.00240
27/27 [==============================] - 1s 23ms/step - loss: 0.0060
Epoch 846/1000
27/27 [==============================] - ETA: 0s - loss: 0.0150
Epoch 846: loss did not improve from 0.00240
27/27 [==============================] - 1s 23ms/step - loss: 0.0150
Epoch 847/1000
27/27 [==============================] - ETA: 0s - loss: 0.1220
Epoch 847: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.1220
Epoch 848/1000
27/27 [==============================] - ETA: 0s - loss: 0.0620
Epoch 848: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0620
Epoch 849/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0382
Epoch 849: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0409
Epoch 850/1000
26/27 [===========================&gt;..] - ETA: 0s - loss: 0.0266
Epoch 850: loss did not improve from 0.00240
27/27 [==============================] - 1s 23ms/step - loss: 0.0260
Epoch 851/1000
27/27 [==============================] - ETA: 0s - loss: 0.0175
Epoch 851: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0175
Epoch 852/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0139
Epoch 852: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0134
Epoch 853/1000
27/27 [==============================] - ETA: 0s - loss: 0.0129
Epoch 853: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0129
Epoch 854/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0103
Epoch 854: loss did not improve from 0.00240
27/27 [==============================] - 1s 21ms/step - loss: 0.0098
Epoch 855/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0105
Epoch 855: loss did not improve from 0.00240
27/27 [==============================] - 1s 21ms/step - loss: 0.0100
Epoch 856/1000
26/27 [===========================&gt;..] - ETA: 0s - loss: 0.0080
Epoch 856: loss did not improve from 0.00240
27/27 [==============================] - 1s 23ms/step - loss: 0.0079
Epoch 857/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0075
Epoch 857: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0073
Epoch 858/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0090
Epoch 858: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0091
Epoch 859/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0073
Epoch 859: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0072
Epoch 860/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0056
Epoch 860: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0054
Epoch 861/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0058
Epoch 861: loss did not improve from 0.00240
27/27 [==============================] - 1s 23ms/step - loss: 0.0055
Epoch 862/1000
27/27 [==============================] - ETA: 0s - loss: 0.0044
Epoch 862: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0044
Epoch 863/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0049
Epoch 863: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0046
Epoch 864/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0044
Epoch 864: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0049
Epoch 865/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0048
Epoch 865: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0048
Epoch 866/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0051
Epoch 866: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0050
Epoch 867/1000
26/27 [===========================&gt;..] - ETA: 0s - loss: 0.0036
Epoch 867: loss did not improve from 0.00240
27/27 [==============================] - 1s 23ms/step - loss: 0.0036
Epoch 868/1000
27/27 [==============================] - ETA: 0s - loss: 0.0047
Epoch 868: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0047
Epoch 869/1000
27/27 [==============================] - ETA: 0s - loss: 0.0040
Epoch 869: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0040
Epoch 870/1000
27/27 [==============================] - ETA: 0s - loss: 0.0039
Epoch 870: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0039
Epoch 871/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0042
Epoch 871: loss did not improve from 0.00240
27/27 [==============================] - 1s 23ms/step - loss: 0.0041
Epoch 872/1000
26/27 [===========================&gt;..] - ETA: 0s - loss: 0.0039
Epoch 872: loss did not improve from 0.00240
27/27 [==============================] - 1s 23ms/step - loss: 0.0038
Epoch 873/1000
26/27 [===========================&gt;..] - ETA: 0s - loss: 0.0043
Epoch 873: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0042
Epoch 874/1000
27/27 [==============================] - ETA: 0s - loss: 0.0032
Epoch 874: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0032
Epoch 875/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0028
Epoch 875: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0036
Epoch 876/1000
27/27 [==============================] - ETA: 0s - loss: 0.0037
Epoch 876: loss did not improve from 0.00240
27/27 [==============================] - 1s 23ms/step - loss: 0.0037
Epoch 877/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0042
Epoch 877: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0040
Epoch 878/1000
27/27 [==============================] - ETA: 0s - loss: 0.0032
Epoch 878: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0032
Epoch 879/1000
27/27 [==============================] - ETA: 0s - loss: 0.0040
Epoch 879: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0040
Epoch 880/1000
27/27 [==============================] - ETA: 0s - loss: 0.0038
Epoch 880: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0038
Epoch 881/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0036
Epoch 881: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0036
Epoch 882/1000
26/27 [===========================&gt;..] - ETA: 0s - loss: 0.0034
Epoch 882: loss did not improve from 0.00240
27/27 [==============================] - 1s 23ms/step - loss: 0.0033
Epoch 883/1000
27/27 [==============================] - ETA: 0s - loss: 0.0032
Epoch 883: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0032
Epoch 884/1000
27/27 [==============================] - ETA: 0s - loss: 0.0034
Epoch 884: loss did not improve from 0.00240
27/27 [==============================] - 1s 23ms/step - loss: 0.0034
Epoch 885/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0034
Epoch 885: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0032
Epoch 886/1000
26/27 [===========================&gt;..] - ETA: 0s - loss: 0.0028
Epoch 886: loss did not improve from 0.00240
27/27 [==============================] - 1s 24ms/step - loss: 0.0027
Epoch 887/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0041
Epoch 887: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0038
Epoch 888/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0035
Epoch 888: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0035
Epoch 889/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0035
Epoch 889: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0033
Epoch 890/1000
27/27 [==============================] - ETA: 0s - loss: 0.0030
Epoch 890: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0030
Epoch 891/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0025
Epoch 891: loss did not improve from 0.00240
27/27 [==============================] - 1s 23ms/step - loss: 0.0036
Epoch 892/1000
26/27 [===========================&gt;..] - ETA: 0s - loss: 0.0031
Epoch 892: loss did not improve from 0.00240
27/27 [==============================] - 1s 23ms/step - loss: 0.0030
Epoch 893/1000
26/27 [===========================&gt;..] - ETA: 0s - loss: 0.0035
Epoch 893: loss did not improve from 0.00240
27/27 [==============================] - 1s 23ms/step - loss: 0.0034
Epoch 894/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0022
Epoch 894: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0031
Epoch 895/1000
27/27 [==============================] - ETA: 0s - loss: 0.0035
Epoch 895: loss did not improve from 0.00240
27/27 [==============================] - 1s 23ms/step - loss: 0.0035
Epoch 896/1000
27/27 [==============================] - ETA: 0s - loss: 0.0037
Epoch 896: loss did not improve from 0.00240
27/27 [==============================] - 1s 23ms/step - loss: 0.0037
Epoch 897/1000
26/27 [===========================&gt;..] - ETA: 0s - loss: 0.0023
Epoch 897: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0036
Epoch 898/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0037
Epoch 898: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0036
Epoch 899/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0290
Epoch 899: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0296
Epoch 900/1000
27/27 [==============================] - ETA: 0s - loss: 0.0428
Epoch 900: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0428
Epoch 901/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0207
Epoch 901: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0208
Epoch 902/1000
26/27 [===========================&gt;..] - ETA: 0s - loss: 0.0168
Epoch 902: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0164
Epoch 903/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0130
Epoch 903: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0140
Epoch 904/1000
26/27 [===========================&gt;..] - ETA: 0s - loss: 0.0284
Epoch 904: loss did not improve from 0.00240
27/27 [==============================] - 1s 23ms/step - loss: 0.0294
Epoch 905/1000
27/27 [==============================] - ETA: 0s - loss: 0.0239
Epoch 905: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0239
Epoch 906/1000
26/27 [===========================&gt;..] - ETA: 0s - loss: 0.0125
Epoch 906: loss did not improve from 0.00240
27/27 [==============================] - 1s 23ms/step - loss: 0.0123
Epoch 907/1000
26/27 [===========================&gt;..] - ETA: 0s - loss: 0.0113
Epoch 907: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0110
Epoch 908/1000
27/27 [==============================] - ETA: 0s - loss: 0.0064
Epoch 908: loss did not improve from 0.00240
27/27 [==============================] - 1s 23ms/step - loss: 0.0064
Epoch 909/1000
26/27 [===========================&gt;..] - ETA: 0s - loss: 0.0066
Epoch 909: loss did not improve from 0.00240
27/27 [==============================] - 1s 23ms/step - loss: 0.0064
Epoch 910/1000
27/27 [==============================] - ETA: 0s - loss: 0.0077
Epoch 910: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0077
Epoch 911/1000
27/27 [==============================] - ETA: 0s - loss: 0.0058
Epoch 911: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0058
Epoch 912/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0041
Epoch 912: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0055
Epoch 913/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0048
Epoch 913: loss did not improve from 0.00240
27/27 [==============================] - 1s 21ms/step - loss: 0.0046
Epoch 914/1000
27/27 [==============================] - ETA: 0s - loss: 0.0077
Epoch 914: loss did not improve from 0.00240
27/27 [==============================] - 1s 23ms/step - loss: 0.0077
Epoch 915/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0056
Epoch 915: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0054
Epoch 916/1000
26/27 [===========================&gt;..] - ETA: 0s - loss: 0.0183
Epoch 916: loss did not improve from 0.00240
27/27 [==============================] - 1s 23ms/step - loss: 0.0187
Epoch 917/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0415
Epoch 917: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0419
Epoch 918/1000
26/27 [===========================&gt;..] - ETA: 0s - loss: 0.0250
Epoch 918: loss did not improve from 0.00240
27/27 [==============================] - 1s 23ms/step - loss: 0.0245
Epoch 919/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0158
Epoch 919: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0155
Epoch 920/1000
26/27 [===========================&gt;..] - ETA: 0s - loss: 0.0114
Epoch 920: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0119
Epoch 921/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0172
Epoch 921: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0170
Epoch 922/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0076
Epoch 922: loss did not improve from 0.00240
27/27 [==============================] - 1s 23ms/step - loss: 0.0079
Epoch 923/1000
26/27 [===========================&gt;..] - ETA: 0s - loss: 0.0059
Epoch 923: loss did not improve from 0.00240
27/27 [==============================] - 1s 23ms/step - loss: 0.0058
Epoch 924/1000
26/27 [===========================&gt;..] - ETA: 0s - loss: 0.0041
Epoch 924: loss did not improve from 0.00240
27/27 [==============================] - 1s 23ms/step - loss: 0.0043
Epoch 925/1000
26/27 [===========================&gt;..] - ETA: 0s - loss: 0.0040
Epoch 925: loss did not improve from 0.00240
27/27 [==============================] - 1s 23ms/step - loss: 0.0039
Epoch 926/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0037
Epoch 926: loss did not improve from 0.00240
27/27 [==============================] - 1s 23ms/step - loss: 0.0036
Epoch 927/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0028
Epoch 927: loss did not improve from 0.00240
27/27 [==============================] - 1s 23ms/step - loss: 0.0036
Epoch 928/1000
27/27 [==============================] - ETA: 0s - loss: 0.0038
Epoch 928: loss did not improve from 0.00240
27/27 [==============================] - 1s 23ms/step - loss: 0.0038
Epoch 929/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0038
Epoch 929: loss did not improve from 0.00240
27/27 [==============================] - 1s 23ms/step - loss: 0.0036
Epoch 930/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0019
Epoch 930: loss did not improve from 0.00240
27/27 [==============================] - 1s 23ms/step - loss: 0.0037
Epoch 931/1000
26/27 [===========================&gt;..] - ETA: 0s - loss: 0.0032
Epoch 931: loss did not improve from 0.00240
27/27 [==============================] - 1s 24ms/step - loss: 0.0032
Epoch 932/1000
26/27 [===========================&gt;..] - ETA: 0s - loss: 0.0037
Epoch 932: loss did not improve from 0.00240
27/27 [==============================] - 1s 23ms/step - loss: 0.0037
Epoch 933/1000
27/27 [==============================] - ETA: 0s - loss: 0.0033
Epoch 933: loss did not improve from 0.00240
27/27 [==============================] - 1s 23ms/step - loss: 0.0033
Epoch 934/1000
26/27 [===========================&gt;..] - ETA: 0s - loss: 0.0035
Epoch 934: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0035
Epoch 935/1000
27/27 [==============================] - ETA: 0s - loss: 0.0035
Epoch 935: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0035
Epoch 936/1000
26/27 [===========================&gt;..] - ETA: 0s - loss: 0.0032
Epoch 936: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0034
Epoch 937/1000
27/27 [==============================] - ETA: 0s - loss: 0.0031
Epoch 937: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0031
Epoch 938/1000
27/27 [==============================] - ETA: 0s - loss: 0.0034
Epoch 938: loss did not improve from 0.00240
27/27 [==============================] - 1s 23ms/step - loss: 0.0034
Epoch 939/1000
26/27 [===========================&gt;..] - ETA: 0s - loss: 0.0035
Epoch 939: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0034
Epoch 940/1000
27/27 [==============================] - ETA: 0s - loss: 0.0030
Epoch 940: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0030
Epoch 941/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0039
Epoch 941: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0037
Epoch 942/1000
27/27 [==============================] - ETA: 0s - loss: 0.0031
Epoch 942: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0031
Epoch 943/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0023
Epoch 943: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0033
Epoch 944/1000
27/27 [==============================] - ETA: 0s - loss: 0.0027
Epoch 944: loss did not improve from 0.00240
27/27 [==============================] - 1s 23ms/step - loss: 0.0027
Epoch 945/1000
27/27 [==============================] - ETA: 0s - loss: 0.0034
Epoch 945: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0034
Epoch 946/1000
26/27 [===========================&gt;..] - ETA: 0s - loss: 0.0031
Epoch 946: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0030
Epoch 947/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0037
Epoch 947: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0035
Epoch 948/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0031
Epoch 948: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0029
Epoch 949/1000
27/27 [==============================] - ETA: 0s - loss: 0.0037
Epoch 949: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0037
Epoch 950/1000
26/27 [===========================&gt;..] - ETA: 0s - loss: 0.0037
Epoch 950: loss did not improve from 0.00240
27/27 [==============================] - 1s 23ms/step - loss: 0.0036
Epoch 951/1000
27/27 [==============================] - ETA: 0s - loss: 0.0032
Epoch 951: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0032
Epoch 952/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0037
Epoch 952: loss did not improve from 0.00240
27/27 [==============================] - 1s 23ms/step - loss: 0.0034
Epoch 953/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0031
Epoch 953: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0031
Epoch 954/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0032
Epoch 954: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0031
Epoch 955/1000
26/27 [===========================&gt;..] - ETA: 0s - loss: 0.0026
Epoch 955: loss did not improve from 0.00240
27/27 [==============================] - 1s 23ms/step - loss: 0.0028
Epoch 956/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0026
Epoch 956: loss did not improve from 0.00240
27/27 [==============================] - 1s 23ms/step - loss: 0.0028
Epoch 957/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0034
Epoch 957: loss did not improve from 0.00240
27/27 [==============================] - 1s 23ms/step - loss: 0.0032
Epoch 958/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0040
Epoch 958: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0038
Epoch 959/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0033
Epoch 959: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0031
Epoch 960/1000
26/27 [===========================&gt;..] - ETA: 0s - loss: 0.0030
Epoch 960: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0030
Epoch 961/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0032
Epoch 961: loss did not improve from 0.00240
27/27 [==============================] - 1s 23ms/step - loss: 0.0031
Epoch 962/1000
27/27 [==============================] - ETA: 0s - loss: 0.0037
Epoch 962: loss did not improve from 0.00240
27/27 [==============================] - 1s 23ms/step - loss: 0.0037
Epoch 963/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0034
Epoch 963: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0032
Epoch 964/1000
27/27 [==============================] - ETA: 0s - loss: 0.0030
Epoch 964: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0030
Epoch 965/1000
27/27 [==============================] - ETA: 0s - loss: 0.0031
Epoch 965: loss did not improve from 0.00240
27/27 [==============================] - 1s 23ms/step - loss: 0.0031
Epoch 966/1000
27/27 [==============================] - ETA: 0s - loss: 0.0027
Epoch 966: loss did not improve from 0.00240
27/27 [==============================] - 1s 23ms/step - loss: 0.0027
Epoch 967/1000
26/27 [===========================&gt;..] - ETA: 0s - loss: 0.0031
Epoch 967: loss did not improve from 0.00240
27/27 [==============================] - 1s 23ms/step - loss: 0.0031
Epoch 968/1000
27/27 [==============================] - ETA: 0s - loss: 0.0029
Epoch 968: loss did not improve from 0.00240
27/27 [==============================] - 1s 23ms/step - loss: 0.0029
Epoch 969/1000
26/27 [===========================&gt;..] - ETA: 0s - loss: 0.0037
Epoch 969: loss did not improve from 0.00240
27/27 [==============================] - 1s 23ms/step - loss: 0.0036
Epoch 970/1000
27/27 [==============================] - ETA: 0s - loss: 0.0034
Epoch 970: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0034
Epoch 971/1000
26/27 [===========================&gt;..] - ETA: 0s - loss: 0.0030
Epoch 971: loss did not improve from 0.00240
27/27 [==============================] - 1s 24ms/step - loss: 0.0029
Epoch 972/1000
27/27 [==============================] - ETA: 0s - loss: 0.0033
Epoch 972: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0033
Epoch 973/1000
27/27 [==============================] - ETA: 0s - loss: 0.0030
Epoch 973: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0030
Epoch 974/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0026
Epoch 974: loss did not improve from 0.00240
27/27 [==============================] - 1s 23ms/step - loss: 0.0025
Epoch 975/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0031
Epoch 975: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0030
Epoch 976/1000
26/27 [===========================&gt;..] - ETA: 0s - loss: 0.0028
Epoch 976: loss did not improve from 0.00240
27/27 [==============================] - 1s 23ms/step - loss: 0.0027
Epoch 977/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0030
Epoch 977: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0029
Epoch 978/1000
26/27 [===========================&gt;..] - ETA: 0s - loss: 0.0026
Epoch 978: loss did not improve from 0.00240
27/27 [==============================] - 1s 23ms/step - loss: 0.0026
Epoch 979/1000
27/27 [==============================] - ETA: 0s - loss: 0.0028
Epoch 979: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0028
Epoch 980/1000
26/27 [===========================&gt;..] - ETA: 0s - loss: 0.0038
Epoch 980: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0037
Epoch 981/1000
27/27 [==============================] - ETA: 0s - loss: 0.0029
Epoch 981: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0029
Epoch 982/1000
26/27 [===========================&gt;..] - ETA: 0s - loss: 0.0036
Epoch 982: loss did not improve from 0.00240
27/27 [==============================] - 1s 23ms/step - loss: 0.0035
Epoch 983/1000
27/27 [==============================] - ETA: 0s - loss: 0.0027
Epoch 983: loss did not improve from 0.00240
27/27 [==============================] - 1s 23ms/step - loss: 0.0027
Epoch 984/1000
26/27 [===========================&gt;..] - ETA: 0s - loss: 0.0032
Epoch 984: loss did not improve from 0.00240
27/27 [==============================] - 1s 23ms/step - loss: 0.0032
Epoch 985/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0020
Epoch 985: loss did not improve from 0.00240
27/27 [==============================] - 1s 23ms/step - loss: 0.0029
Epoch 986/1000
27/27 [==============================] - ETA: 0s - loss: 0.0030
Epoch 986: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0030
Epoch 987/1000
27/27 [==============================] - ETA: 0s - loss: 0.0029
Epoch 987: loss did not improve from 0.00240
27/27 [==============================] - 1s 24ms/step - loss: 0.0029
Epoch 988/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0021
Epoch 988: loss did not improve from 0.00240
27/27 [==============================] - 1s 21ms/step - loss: 0.0030
Epoch 989/1000
25/27 [==========================&gt;...] - ETA: 0s - loss: 0.0184
Epoch 989: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0207
Epoch 990/1000
27/27 [==============================] - ETA: 0s - loss: 0.0606
Epoch 990: loss did not improve from 0.00240
27/27 [==============================] - 1s 24ms/step - loss: 0.0606
Epoch 991/1000
27/27 [==============================] - ETA: 0s - loss: 0.0384
Epoch 991: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0384
Epoch 992/1000
26/27 [===========================&gt;..] - ETA: 0s - loss: 0.0329
Epoch 992: loss did not improve from 0.00240
27/27 [==============================] - 1s 23ms/step - loss: 0.0322
Epoch 993/1000
27/27 [==============================] - ETA: 0s - loss: 0.0219
Epoch 993: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0219
Epoch 994/1000
27/27 [==============================] - ETA: 0s - loss: 0.0124
Epoch 994: loss did not improve from 0.00240
27/27 [==============================] - 1s 23ms/step - loss: 0.0124
Epoch 995/1000
27/27 [==============================] - ETA: 0s - loss: 0.0123
Epoch 995: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0123
Epoch 996/1000
27/27 [==============================] - ETA: 0s - loss: 0.0087
Epoch 996: loss did not improve from 0.00240
27/27 [==============================] - 1s 23ms/step - loss: 0.0087
Epoch 997/1000
26/27 [===========================&gt;..] - ETA: 0s - loss: 0.0092
Epoch 997: loss did not improve from 0.00240
27/27 [==============================] - 1s 23ms/step - loss: 0.0090
Epoch 998/1000
27/27 [==============================] - ETA: 0s - loss: 0.0125
Epoch 998: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0125
Epoch 999/1000
27/27 [==============================] - ETA: 0s - loss: 0.0128
Epoch 999: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0128
Epoch 1000/1000
27/27 [==============================] - ETA: 0s - loss: 0.0084
Epoch 1000: loss did not improve from 0.00240
27/27 [==============================] - 1s 22ms/step - loss: 0.0084</code></pre>
</div>
</div>
<p>Вы увидите разные результаты из-за стохастической природы модели и из-за того, что трудно подобрать случайное начальное число для моделей LSTM, чтобы получить 100% воспроизводимые результаты. Это не касается этой генеративной модели.</p>
<p>После запуска примера у вас должно быть несколько файлов контрольных точек веса в локальном каталоге.</p>
<p>Вы можете удалить их все, кроме одного с наименьшим значением потери. Например, когда я запускал этот пример, ниже был контрольный пункт с наименьшей потерей, которую я достиг.</p>
<p><code>weights-improvement-456-0.0024.hdf5</code></p>
<div class="cell" data-executioninfo="{&quot;elapsed&quot;:312,&quot;status&quot;:&quot;ok&quot;,&quot;timestamp&quot;:1673017655392,&quot;user&quot;:{&quot;displayName&quot;:&quot;Vladimir Orlenko&quot;,&quot;userId&quot;:&quot;14647639487768811794&quot;},&quot;user_tz&quot;:-360}" data-outputid="9738cf9e-0bdd-4607-b41a-3a3a4bd60f1c">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb23"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(history.history.keys())</span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true" tabindex="-1"></a>model.metrics_names</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="136">
<pre><code>['loss']</code></pre>
</div>
</div>
<div class="cell" data-executioninfo="{&quot;elapsed&quot;:1157,&quot;status&quot;:&quot;ok&quot;,&quot;timestamp&quot;:1673070212050,&quot;user&quot;:{&quot;displayName&quot;:&quot;Vladimir Orlenko&quot;,&quot;userId&quot;:&quot;14647639487768811794&quot;},&quot;user_tz&quot;:-360}" data-outputid="eb1aa286-7c2b-49bb-d571-84ed5af4773e">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb25"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a>plt.plot(history.history[<span class="st">'loss'</span>])</span>
<span id="cb25-2"><a href="#cb25-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-3"><a href="#cb25-3" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'model loss'</span>)</span>
<span id="cb25-4"><a href="#cb25-4" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'loss'</span>)</span>
<span id="cb25-5"><a href="#cb25-5" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'epoch'</span>)</span>
<span id="cb25-6"><a href="#cb25-6" aria-hidden="true" tabindex="-1"></a>plt.legend([<span class="st">'train'</span>, <span class="st">'val'</span>], loc<span class="op">=</span><span class="st">'upper right'</span>)</span>
<span id="cb25-7"><a href="#cb25-7" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<div id="fig-loss" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="rnn_mario_level_builder_files/figure-html/fig-loss-output-1.png" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">Figure&nbsp;1: График потерь на обучении</figcaption>
</figure>
</div>
</div>
</div>
<p>#Генерация текста с помощью сети LSTM</p>
<p>Генерация текста с использованием обученной сети LSTM относительно проста.</p>
<p>Во-первых, мы загружаем данные и определяем сеть точно таким же образом, за исключением того, что веса сети загружаются из файла контрольных точек, и сеть не нуждается в обучении.</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb26"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a><span class="co"># load the network weights</span></span>
<span id="cb26-2"><a href="#cb26-2" aria-hidden="true" tabindex="-1"></a>filename <span class="op">=</span> <span class="st">"/content/drive/MyDrive/Проекты/ML/Pets/rnn_mario_level_builder/data/weights-improvement-456-0.0024.hdf5"</span></span>
<span id="cb26-3"><a href="#cb26-3" aria-hidden="true" tabindex="-1"></a>model.load_weights(filename)</span>
<span id="cb26-4"><a href="#cb26-4" aria-hidden="true" tabindex="-1"></a>model.<span class="bu">compile</span>(loss<span class="op">=</span><span class="st">'categorical_crossentropy'</span>, optimizer<span class="op">=</span><span class="st">'adam'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>Кроме того, при подготовке сопоставления уникальных символов с целыми числами мы также должны создать обратное отображение, которое мы можем использовать для преобразования целых чисел обратно в символы, чтобы мы могли понять предсказания.</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb27"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a>int_to_char <span class="op">=</span> <span class="bu">dict</span>((i, c) <span class="cf">for</span> i, c <span class="kw">in</span> <span class="bu">enumerate</span>(chars))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>Наконец, нам нужно делать прогнозы.</p>
<p>Простейший способ использования модели Keras LSTM для прогнозирования - сначала начать с последовательности начальных чисел в качестве входных данных, сгенерировать следующий символ, затем обновить последовательность начальных чисел, чтобы добавить сгенерированный символ в конце, и обрезать первый символ. Этот процесс повторяется до тех пор, пока мы хотим предсказать новые символы (например, последовательность длиной 1000 символов).</p>
<p>Мы можем выбрать случайный шаблон ввода в качестве нашей начальной последовательности, а затем распечатать сгенерированные символы по мере их генерации.</p>
<div class="cell" data-executioninfo="{&quot;elapsed&quot;:23815,&quot;status&quot;:&quot;ok&quot;,&quot;timestamp&quot;:1673070268518,&quot;user&quot;:{&quot;displayName&quot;:&quot;Vladimir Orlenko&quot;,&quot;userId&quot;:&quot;14647639487768811794&quot;},&quot;user_tz&quot;:-360}" data-outputid="14754217-cf26-415a-a6fc-b0c2741c357a">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb28"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> sys</span>
<span id="cb28-2"><a href="#cb28-2" aria-hidden="true" tabindex="-1"></a><span class="co"># pick a random seed</span></span>
<span id="cb28-3"><a href="#cb28-3" aria-hidden="true" tabindex="-1"></a>start <span class="op">=</span> np.random.randint(<span class="dv">0</span>, <span class="bu">len</span>(dataX)<span class="op">-</span><span class="dv">1</span>)</span>
<span id="cb28-4"><a href="#cb28-4" aria-hidden="true" tabindex="-1"></a>pattern <span class="op">=</span> dataX[start]</span>
<span id="cb28-5"><a href="#cb28-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-6"><a href="#cb28-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Seed:"</span>)</span>
<span id="cb28-7"><a href="#cb28-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\"</span><span class="st">"</span>, <span class="st">''</span>.join([int_to_char[value] <span class="cf">for</span> value <span class="kw">in</span> pattern]), <span class="st">"</span><span class="ch">\"</span><span class="st">"</span>)</span>
<span id="cb28-8"><a href="#cb28-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-9"><a href="#cb28-9" aria-hidden="true" tabindex="-1"></a><span class="co"># generate characters</span></span>
<span id="cb28-10"><a href="#cb28-10" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">500</span>):</span>
<span id="cb28-11"><a href="#cb28-11" aria-hidden="true" tabindex="-1"></a>    x <span class="op">=</span> np.reshape(pattern, (<span class="dv">1</span>, <span class="bu">len</span>(pattern), <span class="dv">1</span>))</span>
<span id="cb28-12"><a href="#cb28-12" aria-hidden="true" tabindex="-1"></a>    x <span class="op">=</span> x <span class="op">/</span> <span class="bu">float</span>(n_vocab)</span>
<span id="cb28-13"><a href="#cb28-13" aria-hidden="true" tabindex="-1"></a>    prediction <span class="op">=</span> model.predict(x, verbose<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb28-14"><a href="#cb28-14" aria-hidden="true" tabindex="-1"></a>    index <span class="op">=</span> np.argmax(prediction)</span>
<span id="cb28-15"><a href="#cb28-15" aria-hidden="true" tabindex="-1"></a>    result <span class="op">=</span> int_to_char[index]</span>
<span id="cb28-16"><a href="#cb28-16" aria-hidden="true" tabindex="-1"></a>    seq_in <span class="op">=</span> [int_to_char[value] <span class="cf">for</span> value <span class="kw">in</span> pattern]</span>
<span id="cb28-17"><a href="#cb28-17" aria-hidden="true" tabindex="-1"></a>    sys.stdout.write(result)</span>
<span id="cb28-18"><a href="#cb28-18" aria-hidden="true" tabindex="-1"></a>    pattern.append(index)</span>
<span id="cb28-19"><a href="#cb28-19" aria-hidden="true" tabindex="-1"></a>    pattern <span class="op">=</span> pattern[<span class="dv">1</span>:<span class="bu">len</span>(pattern)]</span>
<span id="cb28-20"><a href="#cb28-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-21"><a href="#cb28-21" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Done."</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Seed:
" -------#GG
-----------##GG
----------###GG
---------####GG
---------####GG
---------------
---------------
---------####GG
----------###GG
-----------##GG
----- "
-------#GG
-------------GG
-------------GG
-------------GG
-------------GG
-----------PPGG
-----------PPGG
-------------GG
-------------GG
-------------GG
---------=---GG
---------=---GG
---------?---GG
---------=---GG
-------------GG
-------------GG
-------------GG
-------------GG
-------------GG
-------------GG
-------------GG
-----------PPGG
-----------PPGG
------------#GG
-----------##GG
----------###GG
---------####GG
--------#####GG
-------######GG
------#######GG
-----########GG
-----####
Done.</code></pre>
</div>
</div>



</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->



</body></html>