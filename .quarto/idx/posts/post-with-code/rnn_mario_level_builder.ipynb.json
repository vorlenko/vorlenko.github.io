{"title":"Create Mario Levels","markdown":{"yaml":{"title":"Create Mario Levels","author":"Vladimir Orlenko","date":"2023-07-29","categories":["code"],"image":"image/super_mario_cyber.jpg","format":{"html":{"code-fold":true}},"jupyter":"python3"},"containsRefs":false,"markdown":"\n\nпо адресу https://nesmaps.com/maps/SuperMarioBrothers/SuperMarioBrothers.html размещенв карты уровнем Супер Марио.\n\nВозьмем от-туда [карту](https://nesmaps.com/maps/SuperMarioBrothers/SuperMarioBrosMap1-1.png)\n\n<img src=\"https://nesmaps.com/maps/SuperMarioBrothers/SuperMarioBrosMap1-1.png\">\n\nОткроем ее в gimp. Включим сетку, и текстом прокодируем спрайты\n\n![image.png](attachment:72642b76-41ab-4495-b71e-54f2bf9880e6.png)\n\nВ результате получаем текстовый файл описывающий препятствия\n\n\n![image.png](attachment:500d0f68-3e01-487f-8edc-f51998c2b4e2.png)\n\nСохраним его, и приступим к написанию кода\n\nСначала мы загрузим данные уровня в переменную `Level`\n\nДанные не годятся для обучения, так как у нас всего 15 строк и 255 признаков. Если повернем набор, то у нас будет 15 признаков и 255 строк, что уже лучше.\n\nТеперь можно приступать к сборке и обучению модели\n\nМы видим, что набор содержит более 3000 символов и что при преобразовании в словаре есть только 14 различных символов для изучения сетью. Гораздо меньше, чем 32 в алфавите.\n\nТеперь нам нужно определить данные обучения для сети. Есть множество вариантов по разбиению текста и подаче его в сеть во время обучения.\n\nНа этом этапе мы разделим текст на подпоследовательности с фиксированной длиной в 160 символов.\n\nКаждый обучающий шаблон сети состоит из 160 временных шагов одного символа (X), за которыми следует один символьный вывод (y). При создании этих последовательностей мы перемещаем это окно по всей книге по одному символу за раз, позволяя каждому символу получить шанс из 160 предшествующих ему символов (кроме, конечно, первых 160 символов).\n\nТеперь, когда мы подготовили наши тренировочные данные, нам нужно преобразовать их так, чтобы они подходили для использования с Keras.\n\nСначала мы должны преобразовать список входных последовательностей в форму[образцы, временные шаги, особенности]ожидается сетью LSTM.\n\nЗатем нам нужно изменить масштаб целых чисел в диапазоне от 0 до 1, чтобы облегчить изучение шаблонов сетью LSTM, которая по умолчанию использует функцию активации сигмовидной кишки.\n\nНаконец, нам нужно преобразовать выходные шаблоны (отдельные символы, преобразованные в целые числа) в одну горячую кодировку. Это сделано для того, чтобы мы могли настроить сеть так, чтобы она предсказывала вероятность каждого из 14 различных символов в словаре (более простое представление), а не пыталась заставить ее предсказать точно следующий символ. Каждое значение y преобразуется в разреженный вектор длиной 14, полный нулей, за исключением 1 в столбце для буквы (целое число), которую представляет шаблон.\n\nМы можем реализовать эти шаги, как показано ниже.\n\nТеперь мы можем определить нашу модель LSTM. Здесь мы определяем один скрытый слой LSTM с 256 единицами памяти. Сеть использует выпадение с вероятностью 20. Выходной уровень - это Плотный уровень, использующий функцию активации softmax для вывода прогнозирования вероятности для каждого из 14 символов в диапазоне от 0 до 1.\n\nЭта проблема на самом деле представляет собой проблему классификации отдельных символов с 14 классами, и поэтому она определяется как оптимизация потерь в журнале (перекрестная энтропия) с использованием алгоритма оптимизации ADAM по скорости.\n\nТестового набора данных нет. Мы моделируем весь обучающий набор данных, чтобы узнать вероятность каждого персонажа в последовательности.\n\nНас не интересует наиболее точная (точность классификации) модель учебного набора данных. Это будет модель, которая идеально предсказывает каждого символа в наборе обучающих данных. Вместо этого мы заинтересованы в обобщении набора данных, который минимизирует выбранную функцию потерь. Мы ищем баланс между обобщением и переобучением, но без запоминания.\n\nСеть работает медленно (около 300 секунд на эпоху на графическом процессоре Nvidia K520). Из-за медлительности и из-за наших требований по оптимизации мы будем использовать контрольные точки модели для записи всех сетевых весов, чтобы каждый раз регистрировать улучшение потерь в конце эпохи. Мы будем использовать лучший набор весов (наименьшая потеря), чтобы реализовать нашу генеративную модель в следующем разделе.\n\nТеперь мы можем приспособить нашу модель к данным. Здесь мы используем скромное количество из 100 эпох и большой размер пакета из 128 шаблонов.\n\nВы увидите разные результаты из-за стохастической природы модели и из-за того, что трудно подобрать случайное начальное число для моделей LSTM, чтобы получить 100% воспроизводимые результаты. Это не касается этой генеративной модели.\n\nПосле запуска примера у вас должно быть несколько файлов контрольных точек веса в локальном каталоге.\n\nВы можете удалить их все, кроме одного с наименьшим значением потери. Например, когда я запускал этот пример, ниже был контрольный пункт с наименьшей потерей, которую я достиг.\n\n\n`weights-improvement-456-0.0024.hdf5`\n\n#Генерация текста с помощью сети LSTM\n\nГенерация текста с использованием обученной сети LSTM относительно проста.\n\nВо-первых, мы загружаем данные и определяем сеть точно таким же образом, за исключением того, что веса сети загружаются из файла контрольных точек, и сеть не нуждается в обучении.\n\nКроме того, при подготовке сопоставления уникальных символов с целыми числами мы также должны создать обратное отображение, которое мы можем использовать для преобразования целых чисел обратно в символы, чтобы мы могли понять предсказания.\n\nНаконец, нам нужно делать прогнозы.\n\nПростейший способ использования модели Keras LSTM для прогнозирования - сначала начать с последовательности начальных чисел в качестве входных данных, сгенерировать следующий символ, затем обновить последовательность начальных чисел, чтобы добавить сгенерированный символ в конце, и обрезать первый символ. Этот процесс повторяется до тех пор, пока мы хотим предсказать новые символы (например, последовательность длиной 1000 символов).\n\nМы можем выбрать случайный шаблон ввода в качестве нашей начальной последовательности, а затем распечатать сгенерированные символы по мере их генерации.\n","srcMarkdownNoYaml":"\n\nпо адресу https://nesmaps.com/maps/SuperMarioBrothers/SuperMarioBrothers.html размещенв карты уровнем Супер Марио.\n\nВозьмем от-туда [карту](https://nesmaps.com/maps/SuperMarioBrothers/SuperMarioBrosMap1-1.png)\n\n<img src=\"https://nesmaps.com/maps/SuperMarioBrothers/SuperMarioBrosMap1-1.png\">\n\nОткроем ее в gimp. Включим сетку, и текстом прокодируем спрайты\n\n![image.png](attachment:72642b76-41ab-4495-b71e-54f2bf9880e6.png)\n\nВ результате получаем текстовый файл описывающий препятствия\n\n\n![image.png](attachment:500d0f68-3e01-487f-8edc-f51998c2b4e2.png)\n\nСохраним его, и приступим к написанию кода\n\nСначала мы загрузим данные уровня в переменную `Level`\n\nДанные не годятся для обучения, так как у нас всего 15 строк и 255 признаков. Если повернем набор, то у нас будет 15 признаков и 255 строк, что уже лучше.\n\nТеперь можно приступать к сборке и обучению модели\n\nМы видим, что набор содержит более 3000 символов и что при преобразовании в словаре есть только 14 различных символов для изучения сетью. Гораздо меньше, чем 32 в алфавите.\n\nТеперь нам нужно определить данные обучения для сети. Есть множество вариантов по разбиению текста и подаче его в сеть во время обучения.\n\nНа этом этапе мы разделим текст на подпоследовательности с фиксированной длиной в 160 символов.\n\nКаждый обучающий шаблон сети состоит из 160 временных шагов одного символа (X), за которыми следует один символьный вывод (y). При создании этих последовательностей мы перемещаем это окно по всей книге по одному символу за раз, позволяя каждому символу получить шанс из 160 предшествующих ему символов (кроме, конечно, первых 160 символов).\n\nТеперь, когда мы подготовили наши тренировочные данные, нам нужно преобразовать их так, чтобы они подходили для использования с Keras.\n\nСначала мы должны преобразовать список входных последовательностей в форму[образцы, временные шаги, особенности]ожидается сетью LSTM.\n\nЗатем нам нужно изменить масштаб целых чисел в диапазоне от 0 до 1, чтобы облегчить изучение шаблонов сетью LSTM, которая по умолчанию использует функцию активации сигмовидной кишки.\n\nНаконец, нам нужно преобразовать выходные шаблоны (отдельные символы, преобразованные в целые числа) в одну горячую кодировку. Это сделано для того, чтобы мы могли настроить сеть так, чтобы она предсказывала вероятность каждого из 14 различных символов в словаре (более простое представление), а не пыталась заставить ее предсказать точно следующий символ. Каждое значение y преобразуется в разреженный вектор длиной 14, полный нулей, за исключением 1 в столбце для буквы (целое число), которую представляет шаблон.\n\nМы можем реализовать эти шаги, как показано ниже.\n\nТеперь мы можем определить нашу модель LSTM. Здесь мы определяем один скрытый слой LSTM с 256 единицами памяти. Сеть использует выпадение с вероятностью 20. Выходной уровень - это Плотный уровень, использующий функцию активации softmax для вывода прогнозирования вероятности для каждого из 14 символов в диапазоне от 0 до 1.\n\nЭта проблема на самом деле представляет собой проблему классификации отдельных символов с 14 классами, и поэтому она определяется как оптимизация потерь в журнале (перекрестная энтропия) с использованием алгоритма оптимизации ADAM по скорости.\n\nТестового набора данных нет. Мы моделируем весь обучающий набор данных, чтобы узнать вероятность каждого персонажа в последовательности.\n\nНас не интересует наиболее точная (точность классификации) модель учебного набора данных. Это будет модель, которая идеально предсказывает каждого символа в наборе обучающих данных. Вместо этого мы заинтересованы в обобщении набора данных, который минимизирует выбранную функцию потерь. Мы ищем баланс между обобщением и переобучением, но без запоминания.\n\nСеть работает медленно (около 300 секунд на эпоху на графическом процессоре Nvidia K520). Из-за медлительности и из-за наших требований по оптимизации мы будем использовать контрольные точки модели для записи всех сетевых весов, чтобы каждый раз регистрировать улучшение потерь в конце эпохи. Мы будем использовать лучший набор весов (наименьшая потеря), чтобы реализовать нашу генеративную модель в следующем разделе.\n\nТеперь мы можем приспособить нашу модель к данным. Здесь мы используем скромное количество из 100 эпох и большой размер пакета из 128 шаблонов.\n\nВы увидите разные результаты из-за стохастической природы модели и из-за того, что трудно подобрать случайное начальное число для моделей LSTM, чтобы получить 100% воспроизводимые результаты. Это не касается этой генеративной модели.\n\nПосле запуска примера у вас должно быть несколько файлов контрольных точек веса в локальном каталоге.\n\nВы можете удалить их все, кроме одного с наименьшим значением потери. Например, когда я запускал этот пример, ниже был контрольный пункт с наименьшей потерей, которую я достиг.\n\n\n`weights-improvement-456-0.0024.hdf5`\n\n#Генерация текста с помощью сети LSTM\n\nГенерация текста с использованием обученной сети LSTM относительно проста.\n\nВо-первых, мы загружаем данные и определяем сеть точно таким же образом, за исключением того, что веса сети загружаются из файла контрольных точек, и сеть не нуждается в обучении.\n\nКроме того, при подготовке сопоставления уникальных символов с целыми числами мы также должны создать обратное отображение, которое мы можем использовать для преобразования целых чисел обратно в символы, чтобы мы могли понять предсказания.\n\nНаконец, нам нужно делать прогнозы.\n\nПростейший способ использования модели Keras LSTM для прогнозирования - сначала начать с последовательности начальных чисел в качестве входных данных, сгенерировать следующий символ, затем обновить последовательность начальных чисел, чтобы добавить сгенерированный символ в конце, и обрезать первый символ. Этот процесс повторяется до тех пор, пока мы хотим предсказать новые символы (например, последовательность длиной 1000 символов).\n\nМы можем выбрать случайный шаблон ввода в качестве нашей начальной последовательности, а затем распечатать сгенерированные символы по мере их генерации.\n"},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":true,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":false,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"engine":"jupyter"},"render":{"keep-tex":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":true,"code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true,"format-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","css":["../../styles.css"],"highlight-style":"espresso","output-file":"rnn_mario_level_builder.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.3.433","theme":"darkly","title-block-banner":true,"title":"Create Mario Levels","author":"Vladimir Orlenko","date":"2023-07-29","categories":["code"],"image":"image/super_mario_cyber.jpg","jupyter":"python3"},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html"]}